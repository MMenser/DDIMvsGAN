{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPuuN7d_iAWh"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "aNKaMwDLhtmQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import imageio\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import make_grid\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import grad as torch_grad\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPIrFdUAj9JM",
        "outputId": "5150f9dc-bd30-4833-ca7b-023d6fdc519f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pn9A9j9h3Qv"
      },
      "source": [
        "# Models.py\n",
        "## Generator and Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "w3W5Kn71g2o8"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, img_size, latent_dim, dim):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.dim = dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_size = img_size\n",
        "        self.feature_sizes = (self.img_size[0] // 16, self.img_size[1] // 16)\n",
        "\n",
        "        self.latent_to_features = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 8 * dim * self.feature_sizes[0] * self.feature_sizes[1]),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.features_to_image = nn.Sequential(\n",
        "            nn.ConvTranspose2d(8 * dim, 4 * dim, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(4 * dim),\n",
        "            nn.ConvTranspose2d(4 * dim, 2 * dim, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(2 * dim),\n",
        "            nn.ConvTranspose2d(2 * dim, dim, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.ConvTranspose2d(dim, self.img_size[2], 4, 2, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        # Map latent into appropriate size for transposed convolutions\n",
        "        x = self.latent_to_features(input_data)\n",
        "        # Reshape\n",
        "        x = x.view(-1, 8 * self.dim, self.feature_sizes[0], self.feature_sizes[1])\n",
        "        # Return generated image\n",
        "        return self.features_to_image(x)\n",
        "\n",
        "    def sample_latent(self, num_samples):\n",
        "        return torch.randn((num_samples, self.latent_dim))\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_size, dim):\n",
        "        \"\"\"\n",
        "        img_size : (int, int, int)\n",
        "            Height and width must be powers of 2.  E.g. (32, 32, 1) or\n",
        "            (64, 128, 3). Last number indicates number of channels, e.g. 1 for\n",
        "            grayscale or 3 for RGB\n",
        "        \"\"\"\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.img_size = img_size\n",
        "\n",
        "        self.image_to_features = nn.Sequential(\n",
        "            nn.Conv2d(self.img_size[2], dim, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(dim, 2 * dim, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(2 * dim, 4 * dim, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(4 * dim, 8 * dim, 4, 2, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # 4 convolutions of stride 2, i.e. halving of size everytime\n",
        "        # So output size will be 8 * (img_size / 2 ^ 4) * (img_size / 2 ^ 4)\n",
        "        output_size = 8 * dim * (img_size[0] // 16) * (img_size[1] // 16)\n",
        "        self.features_to_prob = nn.Sequential(\n",
        "            nn.Linear(output_size, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        batch_size = input_data.size()[0]\n",
        "        x = self.image_to_features(input_data)\n",
        "        x = x.view(batch_size, -1)\n",
        "        return self.features_to_prob(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeVU3p7siMm4"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pnf97xQ3hYoo"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    def __init__(self, generator, discriminator, gen_optimizer, dis_optimizer,\n",
        "                 gp_weight=10, critic_iterations=5, print_every=50,\n",
        "                 use_cuda=False):\n",
        "        self.G = generator\n",
        "        self.G_opt = gen_optimizer\n",
        "        self.D = discriminator\n",
        "        self.D_opt = dis_optimizer\n",
        "        self.losses = {'G': [], 'D': [], 'GP': [], 'gradient_norm': []}\n",
        "        self.num_steps = 0\n",
        "        self.use_cuda = use_cuda\n",
        "        self.gp_weight = gp_weight\n",
        "        self.critic_iterations = critic_iterations\n",
        "        self.print_every = print_every\n",
        "\n",
        "        if self.use_cuda:\n",
        "            self.G.cuda()\n",
        "            self.D.cuda()\n",
        "\n",
        "    def _critic_train_iteration(self, data):\n",
        "        \"\"\" \"\"\"\n",
        "        # Get generated data\n",
        "        batch_size = data.size()[0]\n",
        "        generated_data = self.sample_generator(batch_size)\n",
        "\n",
        "        # Calculate probabilities on real and generated data\n",
        "        data = Variable(data)\n",
        "        if self.use_cuda:\n",
        "            data = data.cuda()\n",
        "        d_real = self.D(data)\n",
        "        d_generated = self.D(generated_data)\n",
        "\n",
        "        # Get gradient penalty\n",
        "        gradient_penalty = self._gradient_penalty(data, generated_data)\n",
        "        self.losses['GP'].append(gradient_penalty.item())\n",
        "\n",
        "        # Create total loss and optimize\n",
        "        self.D_opt.zero_grad()\n",
        "        d_loss = d_generated.mean() - d_real.mean() + gradient_penalty\n",
        "        d_loss.backward()\n",
        "\n",
        "        self.D_opt.step()\n",
        "\n",
        "        # Record loss\n",
        "        self.losses['D'].append(d_loss.item())\n",
        "\n",
        "    def _generator_train_iteration(self, data):\n",
        "        \"\"\" \"\"\"\n",
        "        self.G_opt.zero_grad()\n",
        "\n",
        "        # Get generated data\n",
        "        batch_size = data.size()[0]\n",
        "        generated_data = self.sample_generator(batch_size)\n",
        "\n",
        "        # Calculate loss and optimize\n",
        "        d_generated = self.D(generated_data)\n",
        "        g_loss = - d_generated.mean()\n",
        "        g_loss.backward()\n",
        "        self.G_opt.step()\n",
        "\n",
        "        # Record loss\n",
        "        self.losses['G'].append(g_loss.item())\n",
        "\n",
        "    def _gradient_penalty(self, real_data, generated_data):\n",
        "        batch_size = real_data.size()[0]\n",
        "\n",
        "        # Calculate interpolation\n",
        "        alpha = torch.rand(batch_size, 1, 1, 1)\n",
        "        alpha = alpha.expand_as(real_data)\n",
        "        if self.use_cuda:\n",
        "            alpha = alpha.cuda()\n",
        "        interpolated = alpha * real_data.data + (1 - alpha) * generated_data.data\n",
        "        interpolated = Variable(interpolated, requires_grad=True)\n",
        "        if self.use_cuda:\n",
        "            interpolated = interpolated.cuda()\n",
        "\n",
        "        # Calculate probability of interpolated examples\n",
        "        prob_interpolated = self.D(interpolated)\n",
        "\n",
        "        # Calculate gradients of probabilities with respect to examples\n",
        "        gradients = torch_grad(outputs=prob_interpolated, inputs=interpolated,\n",
        "                               grad_outputs=torch.ones(prob_interpolated.size()).cuda() if self.use_cuda else torch.ones(\n",
        "                               prob_interpolated.size()),\n",
        "                               create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "        # Gradients have shape (batch_size, num_channels, img_width, img_height),\n",
        "        # so flatten to easily take norm per example in batch\n",
        "        gradients = gradients.view(batch_size, -1)\n",
        "        self.losses['gradient_norm'].append(gradients.norm(2, dim=1).mean().item())\n",
        "\n",
        "        # Derivatives of the gradient close to 0 can cause problems because of\n",
        "        # the square root, so manually calculate norm and add epsilon\n",
        "        gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)\n",
        "\n",
        "        # Return gradient penalty\n",
        "        return self.gp_weight * ((gradients_norm - 1) ** 2).mean()\n",
        "\n",
        "    def _train_epoch(self, data_loader):\n",
        "        for i, data in enumerate(data_loader):\n",
        "            self.num_steps += 1\n",
        "            self._critic_train_iteration(data[0])\n",
        "            # Only update generator every |critic_iterations| iterations\n",
        "            if self.num_steps % self.critic_iterations == 0:\n",
        "                self._generator_train_iteration(data[0])\n",
        "\n",
        "            if i % self.print_every == 0:\n",
        "                print(\"Iteration {}\".format(i + 1))\n",
        "                print(\"D: {}\".format(self.losses['D'][-1]))\n",
        "                print(\"GP: {}\".format(self.losses['GP'][-1]))\n",
        "                print(\"Gradient norm: {}\".format(self.losses['gradient_norm'][-1]))\n",
        "                if self.num_steps > self.critic_iterations:\n",
        "                    print(\"G: {}\".format(self.losses['G'][-1]))\n",
        "\n",
        "    def train(self, data_loader, epochs, save_training_gif=True):\n",
        "        if save_training_gif:\n",
        "            # Fix latents to see how image generation improves during training\n",
        "            fixed_latents = Variable(self.G.sample_latent(64))\n",
        "            if self.use_cuda:\n",
        "                fixed_latents = fixed_latents.cuda()\n",
        "            training_progress_images = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print(\"\\nEpoch {}\".format(epoch + 1))\n",
        "            self._train_epoch(data_loader)\n",
        "\n",
        "            if save_training_gif:\n",
        "                # # Generate batch of images and convert to grid\n",
        "                # img_grid = make_grid(self.G(fixed_latents).cpu().data)\n",
        "                # # Convert to numpy and transpose axes to fit imageio convention\n",
        "                # # i.e. (width, height, channels)\n",
        "                # img_grid = np.transpose(img_grid.numpy(), (1, 2, 0))\n",
        "                # # Add image grid to training progress\n",
        "                # training_progress_images.append(img_grid)\n",
        "                grid_t = make_grid(\n",
        "                    self.G(fixed_latents).detach().cpu(),  # detach; no .data\n",
        "                    nrow=8,\n",
        "                    normalize=True,        # scales to [0,1] using min/max per image\n",
        "                    value_range=(0, 1),    # if your generator already outputs [0,1], still OK\n",
        "                    padding=2\n",
        "                )\n",
        "\n",
        "                # 2) Convert CHW -> HWC and to uint8 [0,255]\n",
        "                img_grid = (grid_t.permute(1, 2, 0).numpy() * 255.0).clip(0, 255).astype(np.uint8)\n",
        "\n",
        "                # 3) Append frame\n",
        "                training_progress_images.append(img_grid)\n",
        "\n",
        "        if save_training_gif:\n",
        "            imageio.mimsave('./training_{}_epochs.gif'.format(epochs),\n",
        "                            training_progress_images)\n",
        "\n",
        "    def sample_generator(self, num_samples):\n",
        "        latent_samples = Variable(self.G.sample_latent(num_samples))\n",
        "        if self.use_cuda:\n",
        "            latent_samples = latent_samples.cuda()\n",
        "        generated_data = self.G(latent_samples)\n",
        "        return generated_data\n",
        "\n",
        "    def sample(self, num_samples):\n",
        "        generated_data = self.sample_generator(num_samples)\n",
        "        # Remove color channel\n",
        "        return generated_data.data.cpu().numpy()[:, 0, :, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71CgegNhikBD"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "rWAN7nZkig2u"
      },
      "outputs": [],
      "source": [
        "def get_mnist_dataloaders(batch_size=128):\n",
        "    \"\"\"MNIST dataloader with (32, 32) sized images.\"\"\"\n",
        "    # Resize images so they are a power of 2\n",
        "    all_transforms = transforms.Compose([\n",
        "        transforms.Resize(32),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    # Get train and test data\n",
        "    train_data = datasets.MNIST('../data', train=True, download=True,\n",
        "                                transform=all_transforms)\n",
        "    test_data = datasets.MNIST('../data', train=False,\n",
        "                               transform=all_transforms)\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "def get_fashion_mnist_dataloaders(batch_size=128):\n",
        "    \"\"\"Fashion MNIST dataloader with (32, 32) sized images.\"\"\"\n",
        "    # Resize images so they are a power of 2\n",
        "    all_transforms = transforms.Compose([\n",
        "        transforms.Resize(32),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    # Get train and test data\n",
        "    train_data = datasets.FashionMNIST('../fashion_data', train=True, download=True,\n",
        "                                       transform=all_transforms)\n",
        "    test_data = datasets.FashionMNIST('../fashion_data', train=False,\n",
        "                                      transform=all_transforms)\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "def get_lsun_dataloader(path_to_data='../lsun', dataset='bedroom_train',\n",
        "                        batch_size=64):\n",
        "    \"\"\"LSUN dataloader with (128, 128) sized images.\n",
        "\n",
        "    path_to_data : str\n",
        "        One of 'bedroom_val' or 'bedroom_train'\n",
        "    \"\"\"\n",
        "    # Compose transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(128),\n",
        "        transforms.CenterCrop(128),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # Get dataset\n",
        "    lsun_dset = datasets.LSUN(db_path=path_to_data, classes=[dataset],\n",
        "                              transform=transform)\n",
        "\n",
        "    # Create dataloader\n",
        "    return DataLoader(lsun_dset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtwNjAvyiv_L"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D-tHvtYixEd",
        "outputId": "d3fcbf41-bc7d-47ed-c76e-a6684e8fdc92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (latent_to_features): Sequential(\n",
            "    (0): Linear(in_features=100, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (features_to_image): Sequential(\n",
            "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (7): ReLU()\n",
            "    (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ConvTranspose2d(16, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (10): Sigmoid()\n",
            "  )\n",
            ")\n",
            "Discriminator(\n",
            "  (image_to_features): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): LeakyReLU(negative_slope=0.2)\n",
            "    (4): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "    (6): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (7): Sigmoid()\n",
            "  )\n",
            "  (features_to_prob): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=1, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n",
            "\n",
            "Epoch 1\n",
            "Iteration 1\n",
            "D: 9.981134414672852\n",
            "GP: 9.981154441833496\n",
            "Gradient norm: 0.0009427277254872024\n",
            "Iteration 51\n",
            "D: 9.546013832092285\n",
            "GP: 9.542984962463379\n",
            "Gradient norm: 0.02311868779361248\n",
            "G: -0.502302885055542\n",
            "Iteration 101\n",
            "D: 7.310347557067871\n",
            "GP: 7.2436113357543945\n",
            "Gradient norm: 0.14894120395183563\n",
            "G: -0.5549522042274475\n",
            "Iteration 151\n",
            "D: 4.063673973083496\n",
            "GP: 3.9878602027893066\n",
            "Gradient norm: 0.37024199962615967\n",
            "G: -0.6063655614852905\n",
            "Iteration 201\n",
            "D: 3.035464286804199\n",
            "GP: 3.069166660308838\n",
            "Gradient norm: 0.45662444829940796\n",
            "G: -0.6378489136695862\n",
            "Iteration 251\n",
            "D: 2.6811208724975586\n",
            "GP: 2.7812674045562744\n",
            "Gradient norm: 0.4943738877773285\n",
            "G: -0.6393028497695923\n",
            "Iteration 301\n",
            "D: 2.1150591373443604\n",
            "GP: 2.278942823410034\n",
            "Gradient norm: 0.545009434223175\n",
            "G: -0.6678768992424011\n",
            "Iteration 351\n",
            "D: 2.7516837120056152\n",
            "GP: 2.866978645324707\n",
            "Gradient norm: 0.5069820880889893\n",
            "G: -0.6400210857391357\n",
            "Iteration 401\n",
            "D: 2.2296581268310547\n",
            "GP: 2.3693363666534424\n",
            "Gradient norm: 0.5909786820411682\n",
            "G: -0.6667644381523132\n",
            "Iteration 451\n",
            "D: 1.8572216033935547\n",
            "GP: 2.0096218585968018\n",
            "Gradient norm: 0.6367952823638916\n",
            "G: -0.6621738076210022\n",
            "Iteration 501\n",
            "D: 1.3583612442016602\n",
            "GP: 1.6664725542068481\n",
            "Gradient norm: 0.6810725927352905\n",
            "G: -0.5491023659706116\n",
            "Iteration 551\n",
            "D: 1.553652286529541\n",
            "GP: 1.8162357807159424\n",
            "Gradient norm: 0.7104243040084839\n",
            "G: -0.583430290222168\n",
            "Iteration 601\n",
            "D: 1.0962656736373901\n",
            "GP: 1.3659065961837769\n",
            "Gradient norm: 0.726143479347229\n",
            "G: -0.566664457321167\n",
            "Iteration 651\n",
            "D: 0.8575904369354248\n",
            "GP: 1.1963306665420532\n",
            "Gradient norm: 0.7411951422691345\n",
            "G: -0.5615462064743042\n",
            "Iteration 701\n",
            "D: 0.7858137488365173\n",
            "GP: 1.0582921504974365\n",
            "Gradient norm: 0.8097039461135864\n",
            "G: -0.5654475688934326\n",
            "Iteration 751\n",
            "D: 0.339300274848938\n",
            "GP: 0.6969982385635376\n",
            "Gradient norm: 0.8315916061401367\n",
            "G: -0.500517725944519\n",
            "Iteration 801\n",
            "D: 0.35767126083374023\n",
            "GP: 0.7499254941940308\n",
            "Gradient norm: 0.8061425685882568\n",
            "G: -0.46393921971321106\n",
            "Iteration 851\n",
            "D: 0.41413262486457825\n",
            "GP: 0.8501995205879211\n",
            "Gradient norm: 0.8145492076873779\n",
            "G: -0.4382956027984619\n",
            "Iteration 901\n",
            "D: -0.06887516379356384\n",
            "GP: 0.35801267623901367\n",
            "Gradient norm: 0.9009426832199097\n",
            "G: -0.47520872950553894\n",
            "\n",
            "Epoch 2\n",
            "Iteration 1\n",
            "D: -0.18168535828590393\n",
            "GP: 0.30465367436408997\n",
            "Gradient norm: 0.9167431592941284\n",
            "G: -0.43087702989578247\n",
            "Iteration 51\n",
            "D: 0.10317066311836243\n",
            "GP: 0.5721233487129211\n",
            "Gradient norm: 0.8859716653823853\n",
            "G: -0.366823673248291\n",
            "Iteration 101\n",
            "D: 0.2380213737487793\n",
            "GP: 0.680949330329895\n",
            "Gradient norm: 0.9241819977760315\n",
            "G: -0.388471782207489\n",
            "Iteration 151\n",
            "D: -0.1457725167274475\n",
            "GP: 0.34387850761413574\n",
            "Gradient norm: 0.8916699886322021\n",
            "G: -0.3541417717933655\n",
            "Iteration 201\n",
            "D: -0.39412397146224976\n",
            "GP: 0.15300853550434113\n",
            "Gradient norm: 0.9443101286888123\n",
            "G: -0.36271029710769653\n",
            "Iteration 251\n",
            "D: -0.04558861255645752\n",
            "GP: 0.47965264320373535\n",
            "Gradient norm: 0.8938961029052734\n",
            "G: -0.32140588760375977\n",
            "Iteration 301\n",
            "D: -0.22422164678573608\n",
            "GP: 0.3188944458961487\n",
            "Gradient norm: 0.9392707943916321\n",
            "G: -0.3732147812843323\n",
            "Iteration 351\n",
            "D: -0.15877631306648254\n",
            "GP: 0.42614445090293884\n",
            "Gradient norm: 0.9343904852867126\n",
            "G: -0.3510819673538208\n",
            "Iteration 401\n",
            "D: -0.38967040181159973\n",
            "GP: 0.15038278698921204\n",
            "Gradient norm: 0.9587271213531494\n",
            "G: -0.3677959144115448\n",
            "Iteration 451\n",
            "D: -0.27359136939048767\n",
            "GP: 0.26711776852607727\n",
            "Gradient norm: 0.9530237913131714\n",
            "G: -0.3173704147338867\n",
            "Iteration 501\n",
            "D: -0.016520142555236816\n",
            "GP: 0.5676711797714233\n",
            "Gradient norm: 0.9306347966194153\n",
            "G: -0.3255852460861206\n",
            "Iteration 551\n",
            "D: -0.27944129705429077\n",
            "GP: 0.3503616452217102\n",
            "Gradient norm: 0.9358933568000793\n",
            "G: -0.3314196467399597\n",
            "Iteration 601\n",
            "D: -0.26545530557632446\n",
            "GP: 0.3584330677986145\n",
            "Gradient norm: 0.9447709321975708\n",
            "G: -0.29082542657852173\n",
            "Iteration 651\n",
            "D: -0.501673698425293\n",
            "GP: 0.08922699093818665\n",
            "Gradient norm: 0.9779214262962341\n",
            "G: -0.3527076244354248\n",
            "Iteration 701\n",
            "D: -0.48566824197769165\n",
            "GP: 0.16832812130451202\n",
            "Gradient norm: 0.9729170799255371\n",
            "G: -0.2721988558769226\n",
            "Iteration 751\n",
            "D: -0.44829726219177246\n",
            "GP: 0.21032124757766724\n",
            "Gradient norm: 0.9660556316375732\n",
            "G: -0.2080487459897995\n",
            "Iteration 801\n",
            "D: -0.4250029921531677\n",
            "GP: 0.255393922328949\n",
            "Gradient norm: 0.9627265334129333\n",
            "G: -0.26720479130744934\n",
            "Iteration 851\n",
            "D: -0.4605571925640106\n",
            "GP: 0.1798420250415802\n",
            "Gradient norm: 0.9713144898414612\n",
            "G: -0.24640601873397827\n",
            "Iteration 901\n",
            "D: -0.4846222996711731\n",
            "GP: 0.15852360427379608\n",
            "Gradient norm: 0.9706162810325623\n",
            "G: -0.24041171371936798\n",
            "\n",
            "Epoch 3\n",
            "Iteration 1\n",
            "D: -0.49928778409957886\n",
            "GP: 0.10951690375804901\n",
            "Gradient norm: 1.0144082307815552\n",
            "G: -0.2508181929588318\n",
            "Iteration 51\n",
            "D: -0.5502992868423462\n",
            "GP: 0.11464545130729675\n",
            "Gradient norm: 0.9850702285766602\n",
            "G: -0.23804286122322083\n",
            "Iteration 101\n",
            "D: -0.3175751566886902\n",
            "GP: 0.3097744584083557\n",
            "Gradient norm: 0.9718063473701477\n",
            "G: -0.2499619871377945\n",
            "Iteration 151\n",
            "D: -0.4507324695587158\n",
            "GP: 0.21159343421459198\n",
            "Gradient norm: 1.006955862045288\n",
            "G: -0.26850247383117676\n",
            "Iteration 201\n",
            "D: -0.49667006731033325\n",
            "GP: 0.14701378345489502\n",
            "Gradient norm: 0.9775918126106262\n",
            "G: -0.2673027813434601\n",
            "Iteration 251\n",
            "D: -0.52657550573349\n",
            "GP: 0.12158434838056564\n",
            "Gradient norm: 0.9935082197189331\n",
            "G: -0.25710779428482056\n",
            "Iteration 301\n",
            "D: -0.5382073521614075\n",
            "GP: 0.1351439356803894\n",
            "Gradient norm: 0.9688518047332764\n",
            "G: -0.24700067937374115\n",
            "Iteration 351\n",
            "D: -0.5390926599502563\n",
            "GP: 0.16327235102653503\n",
            "Gradient norm: 0.9564708471298218\n",
            "G: -0.21974366903305054\n",
            "Iteration 401\n",
            "D: -0.5665889978408813\n",
            "GP: 0.11887729167938232\n",
            "Gradient norm: 0.9732531309127808\n",
            "G: -0.21217644214630127\n",
            "Iteration 451\n",
            "D: -0.5138724446296692\n",
            "GP: 0.16128568351268768\n",
            "Gradient norm: 0.9577599763870239\n",
            "G: -0.22160983085632324\n",
            "Iteration 501\n",
            "D: -0.6046496629714966\n",
            "GP: 0.08600412309169769\n",
            "Gradient norm: 1.0085341930389404\n",
            "G: -0.23271821439266205\n",
            "Iteration 551\n",
            "D: -0.48576152324676514\n",
            "GP: 0.15222080051898956\n",
            "Gradient norm: 1.0083458423614502\n",
            "G: -0.2557210326194763\n",
            "Iteration 601\n",
            "D: -0.6113616228103638\n",
            "GP: 0.09306821972131729\n",
            "Gradient norm: 1.0053199529647827\n",
            "G: -0.20089009404182434\n",
            "Iteration 651\n",
            "D: -0.4752814769744873\n",
            "GP: 0.19631707668304443\n",
            "Gradient norm: 0.9977258443832397\n",
            "G: -0.2200082540512085\n",
            "Iteration 701\n",
            "D: -0.5522713661193848\n",
            "GP: 0.16492538154125214\n",
            "Gradient norm: 0.9581096768379211\n",
            "G: -0.2053578644990921\n",
            "Iteration 751\n",
            "D: -0.4709569811820984\n",
            "GP: 0.18341629207134247\n",
            "Gradient norm: 0.9562981724739075\n",
            "G: -0.2554802894592285\n",
            "Iteration 801\n",
            "D: -0.5521351099014282\n",
            "GP: 0.11774437129497528\n",
            "Gradient norm: 0.9773522615432739\n",
            "G: -0.2338174283504486\n",
            "Iteration 851\n",
            "D: -0.5542343258857727\n",
            "GP: 0.14969360828399658\n",
            "Gradient norm: 0.9423092603683472\n",
            "G: -0.2045561969280243\n",
            "Iteration 901\n",
            "D: -0.5250810384750366\n",
            "GP: 0.15278661251068115\n",
            "Gradient norm: 0.9749725461006165\n",
            "G: -0.23640871047973633\n",
            "\n",
            "Epoch 4\n",
            "Iteration 1\n",
            "D: -0.5994272232055664\n",
            "GP: 0.10574504733085632\n",
            "Gradient norm: 0.9739086627960205\n",
            "G: -0.208514004945755\n",
            "Iteration 51\n",
            "D: -0.518454909324646\n",
            "GP: 0.1695670187473297\n",
            "Gradient norm: 0.9578022956848145\n",
            "G: -0.21999408304691315\n",
            "Iteration 101\n",
            "D: -0.5537766218185425\n",
            "GP: 0.14882563054561615\n",
            "Gradient norm: 0.9786107540130615\n",
            "G: -0.20713557302951813\n",
            "Iteration 151\n",
            "D: -0.5822486877441406\n",
            "GP: 0.08846922218799591\n",
            "Gradient norm: 0.978029191493988\n",
            "G: -0.22384683787822723\n",
            "Iteration 201\n",
            "D: -0.5669063329696655\n",
            "GP: 0.11921125650405884\n",
            "Gradient norm: 0.9974421858787537\n",
            "G: -0.2088402509689331\n",
            "Iteration 251\n",
            "D: -0.556142270565033\n",
            "GP: 0.14254027605056763\n",
            "Gradient norm: 0.9712429046630859\n",
            "G: -0.19800043106079102\n",
            "Iteration 301\n",
            "D: -0.6201592683792114\n",
            "GP: 0.09416993707418442\n",
            "Gradient norm: 0.9876135587692261\n",
            "G: -0.19950085878372192\n",
            "Iteration 351\n",
            "D: -0.5588328242301941\n",
            "GP: 0.13815397024154663\n",
            "Gradient norm: 0.9869437217712402\n",
            "G: -0.21014565229415894\n",
            "Iteration 401\n",
            "D: -0.605552613735199\n",
            "GP: 0.09270887821912766\n",
            "Gradient norm: 0.9618967175483704\n",
            "G: -0.21908025443553925\n",
            "Iteration 451\n",
            "D: -0.5988979935646057\n",
            "GP: 0.07254476845264435\n",
            "Gradient norm: 0.9987863302230835\n",
            "G: -0.23050327599048615\n",
            "Iteration 501\n",
            "D: -0.5369290709495544\n",
            "GP: 0.13593775033950806\n",
            "Gradient norm: 1.0016885995864868\n",
            "G: -0.2503289580345154\n",
            "Iteration 551\n",
            "D: -0.5703147053718567\n",
            "GP: 0.13090218603610992\n",
            "Gradient norm: 1.0033310651779175\n",
            "G: -0.21905457973480225\n",
            "Iteration 601\n",
            "D: -0.5970702767372131\n",
            "GP: 0.10365892201662064\n",
            "Gradient norm: 0.9950705766677856\n",
            "G: -0.19435781240463257\n",
            "Iteration 651\n",
            "D: -0.6087521314620972\n",
            "GP: 0.11661425232887268\n",
            "Gradient norm: 0.9806653261184692\n",
            "G: -0.18584883213043213\n",
            "Iteration 701\n",
            "D: -0.618287980556488\n",
            "GP: 0.09011824429035187\n",
            "Gradient norm: 1.0047154426574707\n",
            "G: -0.20815786719322205\n",
            "Iteration 751\n",
            "D: -0.6407814621925354\n",
            "GP: 0.08301401138305664\n",
            "Gradient norm: 0.9754947423934937\n",
            "G: -0.18697606027126312\n",
            "Iteration 801\n",
            "D: -0.5704182982444763\n",
            "GP: 0.13493426144123077\n",
            "Gradient norm: 0.9616455435752869\n",
            "G: -0.20258307456970215\n",
            "Iteration 851\n",
            "D: -0.6187692880630493\n",
            "GP: 0.10467761754989624\n",
            "Gradient norm: 0.9903239607810974\n",
            "G: -0.17533636093139648\n",
            "Iteration 901\n",
            "D: -0.5691149234771729\n",
            "GP: 0.14614692330360413\n",
            "Gradient norm: 1.0112450122833252\n",
            "G: -0.1973770260810852\n",
            "\n",
            "Epoch 5\n",
            "Iteration 1\n",
            "D: -0.6145385503768921\n",
            "GP: 0.11020954698324203\n",
            "Gradient norm: 0.9894786477088928\n",
            "G: -0.17308233678340912\n",
            "Iteration 51\n",
            "D: -0.6241790056228638\n",
            "GP: 0.08730129897594452\n",
            "Gradient norm: 0.9994305372238159\n",
            "G: -0.18191227316856384\n",
            "Iteration 101\n",
            "D: -0.5673297047615051\n",
            "GP: 0.14430196583271027\n",
            "Gradient norm: 0.9818701148033142\n",
            "G: -0.1732795238494873\n",
            "Iteration 151\n",
            "D: -0.621478259563446\n",
            "GP: 0.1100573018193245\n",
            "Gradient norm: 0.996073305606842\n",
            "G: -0.19639229774475098\n",
            "Iteration 201\n",
            "D: -0.6761441230773926\n",
            "GP: 0.03695729374885559\n",
            "Gradient norm: 0.9980525970458984\n",
            "G: -0.1854356825351715\n",
            "Iteration 251\n",
            "D: -0.6125314235687256\n",
            "GP: 0.0854291021823883\n",
            "Gradient norm: 0.9979614615440369\n",
            "G: -0.21983389556407928\n",
            "Iteration 301\n",
            "D: -0.5820997357368469\n",
            "GP: 0.12652285397052765\n",
            "Gradient norm: 0.9874581098556519\n",
            "G: -0.20297151803970337\n",
            "Iteration 351\n",
            "D: -0.5627084970474243\n",
            "GP: 0.14820900559425354\n",
            "Gradient norm: 0.9480278491973877\n",
            "G: -0.193803608417511\n",
            "Iteration 401\n",
            "D: -0.5942012667655945\n",
            "GP: 0.07878261804580688\n",
            "Gradient norm: 1.0244024991989136\n",
            "G: -0.19668671488761902\n",
            "Iteration 451\n",
            "D: -0.4986569285392761\n",
            "GP: 0.20180648565292358\n",
            "Gradient norm: 1.0174916982650757\n",
            "G: -0.18492461740970612\n",
            "Iteration 501\n",
            "D: -0.58367919921875\n",
            "GP: 0.11188386380672455\n",
            "Gradient norm: 0.9666407108306885\n",
            "G: -0.20828387141227722\n",
            "Iteration 551\n",
            "D: -0.6055041551589966\n",
            "GP: 0.09556260704994202\n",
            "Gradient norm: 0.9836241006851196\n",
            "G: -0.21322686970233917\n",
            "Iteration 601\n",
            "D: -0.5760059356689453\n",
            "GP: 0.16693785786628723\n",
            "Gradient norm: 0.9482601881027222\n",
            "G: -0.17297306656837463\n",
            "Iteration 651\n",
            "D: -0.6038902997970581\n",
            "GP: 0.12800678610801697\n",
            "Gradient norm: 1.0264370441436768\n",
            "G: -0.1626819670200348\n",
            "Iteration 701\n",
            "D: -0.5975626111030579\n",
            "GP: 0.1308048814535141\n",
            "Gradient norm: 0.9797366857528687\n",
            "G: -0.20122572779655457\n",
            "Iteration 751\n",
            "D: -0.501125693321228\n",
            "GP: 0.21718087792396545\n",
            "Gradient norm: 0.9536275267601013\n",
            "G: -0.18776267766952515\n",
            "Iteration 801\n",
            "D: -0.5795618295669556\n",
            "GP: 0.1093924343585968\n",
            "Gradient norm: 0.9965927600860596\n",
            "G: -0.2213996946811676\n",
            "Iteration 851\n",
            "D: -0.582283079624176\n",
            "GP: 0.09894156455993652\n",
            "Gradient norm: 0.9808756113052368\n",
            "G: -0.19632673263549805\n",
            "Iteration 901\n",
            "D: -0.553095281124115\n",
            "GP: 0.10977379977703094\n",
            "Gradient norm: 0.9765257239341736\n",
            "G: -0.23062750697135925\n",
            "\n",
            "Epoch 6\n",
            "Iteration 1\n",
            "D: -0.6221936941146851\n",
            "GP: 0.058796368539333344\n",
            "Gradient norm: 0.9896931648254395\n",
            "G: -0.23353323340415955\n",
            "Iteration 51\n",
            "D: -0.579687237739563\n",
            "GP: 0.09731586277484894\n",
            "Gradient norm: 0.9843737483024597\n",
            "G: -0.24313892424106598\n",
            "Iteration 101\n",
            "D: -0.5626956224441528\n",
            "GP: 0.13707494735717773\n",
            "Gradient norm: 0.9635481238365173\n",
            "G: -0.20651911199092865\n",
            "Iteration 151\n",
            "D: -0.6085469126701355\n",
            "GP: 0.07830154150724411\n",
            "Gradient norm: 0.9977285861968994\n",
            "G: -0.21436385810375214\n",
            "Iteration 201\n",
            "D: -0.5951302647590637\n",
            "GP: 0.08364103734493256\n",
            "Gradient norm: 1.00822114944458\n",
            "G: -0.23370414972305298\n",
            "Iteration 251\n",
            "D: -0.5835785269737244\n",
            "GP: 0.11285624653100967\n",
            "Gradient norm: 0.9904016256332397\n",
            "G: -0.21464264392852783\n",
            "Iteration 301\n",
            "D: -0.621685266494751\n",
            "GP: 0.09783662855625153\n",
            "Gradient norm: 0.9762783050537109\n",
            "G: -0.19906118512153625\n",
            "Iteration 351\n",
            "D: -0.5559980869293213\n",
            "GP: 0.14072707295417786\n",
            "Gradient norm: 0.9886104464530945\n",
            "G: -0.2120661437511444\n",
            "Iteration 401\n",
            "D: -0.6256250143051147\n",
            "GP: 0.07579031586647034\n",
            "Gradient norm: 1.0192116498947144\n",
            "G: -0.21156638860702515\n",
            "Iteration 451\n",
            "D: -0.5686448812484741\n",
            "GP: 0.11034910380840302\n",
            "Gradient norm: 0.9992445707321167\n",
            "G: -0.22220540046691895\n",
            "Iteration 501\n",
            "D: -0.5916545987129211\n",
            "GP: 0.10394509881734848\n",
            "Gradient norm: 0.9823246002197266\n",
            "G: -0.21024730801582336\n",
            "Iteration 551\n",
            "D: -0.6186487078666687\n",
            "GP: 0.0891280546784401\n",
            "Gradient norm: 0.9983446598052979\n",
            "G: -0.20604942739009857\n",
            "Iteration 601\n",
            "D: -0.5549191832542419\n",
            "GP: 0.10978744924068451\n",
            "Gradient norm: 1.0034271478652954\n",
            "G: -0.26060861349105835\n",
            "Iteration 651\n",
            "D: -0.6275498867034912\n",
            "GP: 0.09082788228988647\n",
            "Gradient norm: 1.0000965595245361\n",
            "G: -0.19368207454681396\n",
            "Iteration 701\n",
            "D: -0.5911062359809875\n",
            "GP: 0.10387871414422989\n",
            "Gradient norm: 0.984349250793457\n",
            "G: -0.2054826021194458\n",
            "Iteration 751\n",
            "D: -0.5839105248451233\n",
            "GP: 0.1397232860326767\n",
            "Gradient norm: 0.9524310827255249\n",
            "G: -0.2071801871061325\n",
            "Iteration 801\n",
            "D: -0.5775344371795654\n",
            "GP: 0.1063891053199768\n",
            "Gradient norm: 0.9879039525985718\n",
            "G: -0.21609002351760864\n",
            "Iteration 851\n",
            "D: -0.5836763381958008\n",
            "GP: 0.12212972342967987\n",
            "Gradient norm: 0.9678257703781128\n",
            "G: -0.19657106697559357\n",
            "Iteration 901\n",
            "D: -0.586779773235321\n",
            "GP: 0.1070062667131424\n",
            "Gradient norm: 0.98616623878479\n",
            "G: -0.20980045199394226\n",
            "\n",
            "Epoch 7\n",
            "Iteration 1\n",
            "D: -0.6006461977958679\n",
            "GP: 0.07897540181875229\n",
            "Gradient norm: 0.9905589818954468\n",
            "G: -0.19661833345890045\n",
            "Iteration 51\n",
            "D: -0.610971212387085\n",
            "GP: 0.09774880111217499\n",
            "Gradient norm: 1.0084880590438843\n",
            "G: -0.19411903619766235\n",
            "Iteration 101\n",
            "D: -0.6328566074371338\n",
            "GP: 0.07930801808834076\n",
            "Gradient norm: 0.9656527042388916\n",
            "G: -0.21361298859119415\n",
            "Iteration 151\n",
            "D: -0.6312518119812012\n",
            "GP: 0.077215775847435\n",
            "Gradient norm: 0.977500855922699\n",
            "G: -0.18480336666107178\n",
            "Iteration 201\n",
            "D: -0.5825362205505371\n",
            "GP: 0.12859058380126953\n",
            "Gradient norm: 1.0091679096221924\n",
            "G: -0.20527420938014984\n",
            "Iteration 251\n",
            "D: -0.5849895477294922\n",
            "GP: 0.10943138599395752\n",
            "Gradient norm: 0.9891970157623291\n",
            "G: -0.18604062497615814\n",
            "Iteration 301\n",
            "D: -0.6173887252807617\n",
            "GP: 0.08390537649393082\n",
            "Gradient norm: 0.9898451566696167\n",
            "G: -0.20371752977371216\n",
            "Iteration 351\n",
            "D: -0.6572449207305908\n",
            "GP: 0.05600370466709137\n",
            "Gradient norm: 0.9886449575424194\n",
            "G: -0.21305906772613525\n",
            "Iteration 401\n",
            "D: -0.6266648173332214\n",
            "GP: 0.07323651760816574\n",
            "Gradient norm: 0.9850928783416748\n",
            "G: -0.18099401891231537\n",
            "Iteration 451\n",
            "D: -0.6162533164024353\n",
            "GP: 0.09745001792907715\n",
            "Gradient norm: 0.9665046334266663\n",
            "G: -0.1805131584405899\n",
            "Iteration 501\n",
            "D: -0.6250951290130615\n",
            "GP: 0.0910397469997406\n",
            "Gradient norm: 0.9791622757911682\n",
            "G: -0.2020607739686966\n",
            "Iteration 551\n",
            "D: -0.6438175439834595\n",
            "GP: 0.08203984051942825\n",
            "Gradient norm: 0.9836848974227905\n",
            "G: -0.19302955269813538\n",
            "Iteration 601\n",
            "D: -0.6594759225845337\n",
            "GP: 0.07620514929294586\n",
            "Gradient norm: 0.9760135412216187\n",
            "G: -0.19741064310073853\n",
            "Iteration 651\n",
            "D: -0.5322222113609314\n",
            "GP: 0.20586960017681122\n",
            "Gradient norm: 0.9783771634101868\n",
            "G: -0.1747831404209137\n",
            "Iteration 701\n",
            "D: -0.6695975065231323\n",
            "GP: 0.06660731136798859\n",
            "Gradient norm: 0.9684802889823914\n",
            "G: -0.17003904283046722\n",
            "Iteration 751\n",
            "D: -0.6814156174659729\n",
            "GP: 0.055495694279670715\n",
            "Gradient norm: 0.9969446063041687\n",
            "G: -0.17433686554431915\n",
            "Iteration 801\n",
            "D: -0.6823247671127319\n",
            "GP: 0.05505835637450218\n",
            "Gradient norm: 0.9735744595527649\n",
            "G: -0.15922661125659943\n",
            "Iteration 851\n",
            "D: -0.6220009922981262\n",
            "GP: 0.11441318690776825\n",
            "Gradient norm: 1.0029568672180176\n",
            "G: -0.17136713862419128\n",
            "Iteration 901\n",
            "D: -0.6818611025810242\n",
            "GP: 0.0840940922498703\n",
            "Gradient norm: 0.9691200852394104\n",
            "G: -0.1573239266872406\n",
            "\n",
            "Epoch 8\n",
            "Iteration 1\n",
            "D: -0.6410638093948364\n",
            "GP: 0.07606767117977142\n",
            "Gradient norm: 1.001031756401062\n",
            "G: -0.186118483543396\n",
            "Iteration 51\n",
            "D: -0.6161984205245972\n",
            "GP: 0.09346279501914978\n",
            "Gradient norm: 1.0211303234100342\n",
            "G: -0.20933085680007935\n",
            "Iteration 101\n",
            "D: -0.5355370044708252\n",
            "GP: 0.10165676474571228\n",
            "Gradient norm: 0.9799082279205322\n",
            "G: -0.2177017331123352\n",
            "Iteration 151\n",
            "D: -0.6317567825317383\n",
            "GP: 0.06785022467374802\n",
            "Gradient norm: 0.9777266383171082\n",
            "G: -0.17008037865161896\n",
            "Iteration 201\n",
            "D: -0.5935205817222595\n",
            "GP: 0.10108456760644913\n",
            "Gradient norm: 1.000720739364624\n",
            "G: -0.16714775562286377\n",
            "Iteration 251\n",
            "D: -0.6432492733001709\n",
            "GP: 0.06161034107208252\n",
            "Gradient norm: 0.9937900304794312\n",
            "G: -0.17203554511070251\n",
            "Iteration 301\n",
            "D: -0.6635172367095947\n",
            "GP: 0.05265573039650917\n",
            "Gradient norm: 1.01052725315094\n",
            "G: -0.1707070767879486\n",
            "Iteration 351\n",
            "D: -0.6580254435539246\n",
            "GP: 0.07021361589431763\n",
            "Gradient norm: 1.0024826526641846\n",
            "G: -0.16853712499141693\n",
            "Iteration 401\n",
            "D: -0.6002585887908936\n",
            "GP: 0.1509554535150528\n",
            "Gradient norm: 0.9735355973243713\n",
            "G: -0.16578368842601776\n",
            "Iteration 451\n",
            "D: -0.636418879032135\n",
            "GP: 0.0906556099653244\n",
            "Gradient norm: 1.0271377563476562\n",
            "G: -0.16835109889507294\n",
            "Iteration 501\n",
            "D: -0.5388358235359192\n",
            "GP: 0.20679694414138794\n",
            "Gradient norm: 0.9610825777053833\n",
            "G: -0.155557781457901\n",
            "Iteration 551\n",
            "D: -0.6361105442047119\n",
            "GP: 0.09672565758228302\n",
            "Gradient norm: 1.01984703540802\n",
            "G: -0.16127237677574158\n",
            "Iteration 601\n",
            "D: -0.6052708625793457\n",
            "GP: 0.14135880768299103\n",
            "Gradient norm: 0.9974769353866577\n",
            "G: -0.15252448618412018\n",
            "Iteration 651\n",
            "D: -0.6442641019821167\n",
            "GP: 0.08576259762048721\n",
            "Gradient norm: 0.984231173992157\n",
            "G: -0.1637243926525116\n",
            "Iteration 701\n",
            "D: -0.6342078447341919\n",
            "GP: 0.10585549473762512\n",
            "Gradient norm: 0.9803293943405151\n",
            "G: -0.16246260702610016\n",
            "Iteration 751\n",
            "D: -0.6524088382720947\n",
            "GP: 0.0877109169960022\n",
            "Gradient norm: 0.979939341545105\n",
            "G: -0.1677795648574829\n",
            "Iteration 801\n",
            "D: -0.6549137830734253\n",
            "GP: 0.06017661839723587\n",
            "Gradient norm: 0.976719319820404\n",
            "G: -0.16909919679164886\n",
            "Iteration 851\n",
            "D: -0.6534982323646545\n",
            "GP: 0.06602045148611069\n",
            "Gradient norm: 0.9841976761817932\n",
            "G: -0.14542019367218018\n",
            "Iteration 901\n",
            "D: -0.6357022523880005\n",
            "GP: 0.10024764388799667\n",
            "Gradient norm: 0.989071786403656\n",
            "G: -0.13717898726463318\n",
            "\n",
            "Epoch 9\n",
            "Iteration 1\n",
            "D: -0.6560716032981873\n",
            "GP: 0.07871253788471222\n",
            "Gradient norm: 0.9880136251449585\n",
            "G: -0.1442127227783203\n",
            "Iteration 51\n",
            "D: -0.6817649006843567\n",
            "GP: 0.060998618602752686\n",
            "Gradient norm: 0.9913253784179688\n",
            "G: -0.13798388838768005\n",
            "Iteration 101\n",
            "D: -0.6717842221260071\n",
            "GP: 0.06732688844203949\n",
            "Gradient norm: 0.994516909122467\n",
            "G: -0.13472715020179749\n",
            "Iteration 151\n",
            "D: -0.6862716674804688\n",
            "GP: 0.06923249363899231\n",
            "Gradient norm: 0.9780148267745972\n",
            "G: -0.14363497495651245\n",
            "Iteration 201\n",
            "D: -0.6960540413856506\n",
            "GP: 0.04557570442557335\n",
            "Gradient norm: 1.0230218172073364\n",
            "G: -0.16075053811073303\n",
            "Iteration 251\n",
            "D: -0.6679701209068298\n",
            "GP: 0.08897851407527924\n",
            "Gradient norm: 0.9773554801940918\n",
            "G: -0.13961726427078247\n",
            "Iteration 301\n",
            "D: -0.6246175169944763\n",
            "GP: 0.12481541186571121\n",
            "Gradient norm: 0.9953488707542419\n",
            "G: -0.13910406827926636\n",
            "Iteration 351\n",
            "D: -0.6854175329208374\n",
            "GP: 0.06201035901904106\n",
            "Gradient norm: 0.9933555126190186\n",
            "G: -0.13275593519210815\n",
            "Iteration 401\n",
            "D: -0.6352153420448303\n",
            "GP: 0.10778462886810303\n",
            "Gradient norm: 0.9847725629806519\n",
            "G: -0.13096967339515686\n",
            "Iteration 451\n",
            "D: -0.695410966873169\n",
            "GP: 0.07085011154413223\n",
            "Gradient norm: 0.9778900146484375\n",
            "G: -0.11508402228355408\n",
            "Iteration 501\n",
            "D: -0.6907578706741333\n",
            "GP: 0.06529209017753601\n",
            "Gradient norm: 0.9659461379051208\n",
            "G: -0.13616642355918884\n",
            "Iteration 551\n",
            "D: -0.7105902433395386\n",
            "GP: 0.05429590120911598\n",
            "Gradient norm: 0.9914732575416565\n",
            "G: -0.1204628199338913\n",
            "Iteration 601\n",
            "D: -0.6563896536827087\n",
            "GP: 0.09137137234210968\n",
            "Gradient norm: 0.9685994982719421\n",
            "G: -0.1272672414779663\n",
            "Iteration 651\n",
            "D: -0.6520529389381409\n",
            "GP: 0.13406582176685333\n",
            "Gradient norm: 0.9683443307876587\n",
            "G: -0.12752114236354828\n",
            "Iteration 701\n",
            "D: -0.6744173765182495\n",
            "GP: 0.08217678964138031\n",
            "Gradient norm: 0.9903742671012878\n",
            "G: -0.12329405546188354\n",
            "Iteration 751\n",
            "D: -0.6847922205924988\n",
            "GP: 0.0836624950170517\n",
            "Gradient norm: 0.9946268200874329\n",
            "G: -0.12848904728889465\n",
            "Iteration 801\n",
            "D: -0.7116683125495911\n",
            "GP: 0.04866255447268486\n",
            "Gradient norm: 0.9696363210678101\n",
            "G: -0.1131785660982132\n",
            "Iteration 851\n",
            "D: -0.6973181962966919\n",
            "GP: 0.0638563260436058\n",
            "Gradient norm: 0.9758398532867432\n",
            "G: -0.14638590812683105\n",
            "Iteration 901\n",
            "D: -0.6670723557472229\n",
            "GP: 0.07966749370098114\n",
            "Gradient norm: 0.9955233931541443\n",
            "G: -0.1446099728345871\n",
            "\n",
            "Epoch 10\n",
            "Iteration 1\n",
            "D: -0.6678359508514404\n",
            "GP: 0.0665060505270958\n",
            "Gradient norm: 0.9863641262054443\n",
            "G: -0.13769738376140594\n",
            "Iteration 51\n",
            "D: -0.6908848881721497\n",
            "GP: 0.05575869232416153\n",
            "Gradient norm: 0.9862073659896851\n",
            "G: -0.12432794272899628\n",
            "Iteration 101\n",
            "D: -0.6936705708503723\n",
            "GP: 0.052996519953012466\n",
            "Gradient norm: 0.9852139949798584\n",
            "G: -0.12452971935272217\n",
            "Iteration 151\n",
            "D: -0.6986994743347168\n",
            "GP: 0.06503033638000488\n",
            "Gradient norm: 0.9965934753417969\n",
            "G: -0.12917788326740265\n",
            "Iteration 201\n",
            "D: -0.7044310569763184\n",
            "GP: 0.05855131894350052\n",
            "Gradient norm: 1.0021913051605225\n",
            "G: -0.11102933436632156\n",
            "Iteration 251\n",
            "D: -0.7208771705627441\n",
            "GP: 0.03913126140832901\n",
            "Gradient norm: 0.9890627861022949\n",
            "G: -0.13692855834960938\n",
            "Iteration 301\n",
            "D: -0.7037461400032043\n",
            "GP: 0.09699146449565887\n",
            "Gradient norm: 0.9940390586853027\n",
            "G: -0.10286419093608856\n",
            "Iteration 351\n",
            "D: -0.7204126715660095\n",
            "GP: 0.04594080150127411\n",
            "Gradient norm: 0.9753888845443726\n",
            "G: -0.11987967789173126\n",
            "Iteration 401\n",
            "D: -0.7199810147285461\n",
            "GP: 0.049249447882175446\n",
            "Gradient norm: 0.9803357124328613\n",
            "G: -0.10260705649852753\n",
            "Iteration 451\n",
            "D: -0.6887197494506836\n",
            "GP: 0.09016137570142746\n",
            "Gradient norm: 0.9792399406433105\n",
            "G: -0.12228401750326157\n",
            "Iteration 501\n",
            "D: -0.7057126760482788\n",
            "GP: 0.06234443932771683\n",
            "Gradient norm: 0.9904395341873169\n",
            "G: -0.12079034745693207\n",
            "Iteration 551\n",
            "D: -0.7085669636726379\n",
            "GP: 0.05761642009019852\n",
            "Gradient norm: 0.9956307411193848\n",
            "G: -0.11574099957942963\n",
            "Iteration 601\n",
            "D: -0.7357099652290344\n",
            "GP: 0.04198616370558739\n",
            "Gradient norm: 0.994999349117279\n",
            "G: -0.09746434539556503\n",
            "Iteration 651\n",
            "D: -0.7059849500656128\n",
            "GP: 0.1021348387002945\n",
            "Gradient norm: 0.9995415806770325\n",
            "G: -0.10732146352529526\n",
            "Iteration 701\n",
            "D: -0.7017368078231812\n",
            "GP: 0.0837428867816925\n",
            "Gradient norm: 0.9724425077438354\n",
            "G: -0.11408963054418564\n",
            "Iteration 751\n",
            "D: -0.6881014704704285\n",
            "GP: 0.07415015995502472\n",
            "Gradient norm: 1.000146746635437\n",
            "G: -0.11669672280550003\n",
            "Iteration 801\n",
            "D: -0.7156639099121094\n",
            "GP: 0.06416399031877518\n",
            "Gradient norm: 0.9667301177978516\n",
            "G: -0.12487077713012695\n",
            "Iteration 851\n",
            "D: -0.7149738073348999\n",
            "GP: 0.06228739395737648\n",
            "Gradient norm: 1.002889633178711\n",
            "G: -0.10424380004405975\n",
            "Iteration 901\n",
            "D: -0.727485716342926\n",
            "GP: 0.06132286787033081\n",
            "Gradient norm: 1.0018701553344727\n",
            "G: -0.10178129374980927\n",
            "\n",
            "Epoch 11\n",
            "Iteration 1\n",
            "D: -0.6371076107025146\n",
            "GP: 0.11298046261072159\n",
            "Gradient norm: 0.9874428510665894\n",
            "G: -0.13450901210308075\n",
            "Iteration 51\n",
            "D: -0.6877269148826599\n",
            "GP: 0.06924576312303543\n",
            "Gradient norm: 1.0019001960754395\n",
            "G: -0.11621607095003128\n",
            "Iteration 101\n",
            "D: -0.7196452021598816\n",
            "GP: 0.04825397953391075\n",
            "Gradient norm: 1.0114439725875854\n",
            "G: -0.1358504742383957\n",
            "Iteration 151\n",
            "D: -0.653738260269165\n",
            "GP: 0.06373362243175507\n",
            "Gradient norm: 0.9988378286361694\n",
            "G: -0.1589353084564209\n",
            "Iteration 201\n",
            "D: -0.6617752909660339\n",
            "GP: 0.0885518342256546\n",
            "Gradient norm: 0.9959487318992615\n",
            "G: -0.135267436504364\n",
            "Iteration 251\n",
            "D: -0.6431972980499268\n",
            "GP: 0.12165311723947525\n",
            "Gradient norm: 0.9928018450737\n",
            "G: -0.12760603427886963\n",
            "Iteration 301\n",
            "D: -0.6477919220924377\n",
            "GP: 0.08309971541166306\n",
            "Gradient norm: 1.0160508155822754\n",
            "G: -0.13810846209526062\n",
            "Iteration 351\n",
            "D: -0.671700656414032\n",
            "GP: 0.061401721090078354\n",
            "Gradient norm: 1.0047132968902588\n",
            "G: -0.1408088505268097\n",
            "Iteration 401\n",
            "D: -0.5967235565185547\n",
            "GP: 0.11968936026096344\n",
            "Gradient norm: 0.9650815725326538\n",
            "G: -0.1367272436618805\n",
            "Iteration 451\n",
            "D: -0.7596308588981628\n",
            "GP: 0.03163963928818703\n",
            "Gradient norm: 1.0068721771240234\n",
            "G: -0.10120604932308197\n",
            "Iteration 501\n",
            "D: -0.6241160035133362\n",
            "GP: 0.1330292820930481\n",
            "Gradient norm: 1.0094727277755737\n",
            "G: -0.0978812649846077\n",
            "Iteration 551\n",
            "D: -0.6738664507865906\n",
            "GP: 0.10244067758321762\n",
            "Gradient norm: 0.9890000820159912\n",
            "G: -0.1013120710849762\n",
            "Iteration 601\n",
            "D: -0.7083495855331421\n",
            "GP: 0.0510108657181263\n",
            "Gradient norm: 1.0059928894042969\n",
            "G: -0.12213236093521118\n",
            "Iteration 651\n",
            "D: -0.7218461036682129\n",
            "GP: 0.055859629064798355\n",
            "Gradient norm: 0.9992387890815735\n",
            "G: -0.12172111868858337\n",
            "Iteration 701\n",
            "D: -0.73677659034729\n",
            "GP: 0.031913451850414276\n",
            "Gradient norm: 1.0028196573257446\n",
            "G: -0.11015717685222626\n",
            "Iteration 751\n",
            "D: -0.6924075484275818\n",
            "GP: 0.07392488420009613\n",
            "Gradient norm: 0.985238790512085\n",
            "G: -0.1300812065601349\n",
            "Iteration 801\n",
            "D: -0.6308563351631165\n",
            "GP: 0.09176288545131683\n",
            "Gradient norm: 0.9762943983078003\n",
            "G: -0.12272882461547852\n",
            "Iteration 851\n",
            "D: -0.6683529019355774\n",
            "GP: 0.0928102359175682\n",
            "Gradient norm: 0.9721961617469788\n",
            "G: -0.12144826352596283\n",
            "Iteration 901\n",
            "D: -0.6755890250205994\n",
            "GP: 0.057861339300870895\n",
            "Gradient norm: 0.9945071935653687\n",
            "G: -0.13168835639953613\n",
            "\n",
            "Epoch 12\n",
            "Iteration 1\n",
            "D: -0.6725271940231323\n",
            "GP: 0.07549918442964554\n",
            "Gradient norm: 0.975114643573761\n",
            "G: -0.14206357300281525\n",
            "Iteration 51\n",
            "D: -0.5944684743881226\n",
            "GP: 0.13684971630573273\n",
            "Gradient norm: 0.9880762696266174\n",
            "G: -0.1196625605225563\n",
            "Iteration 101\n",
            "D: -0.6596577167510986\n",
            "GP: 0.0894639641046524\n",
            "Gradient norm: 0.9838560819625854\n",
            "G: -0.12370486557483673\n",
            "Iteration 151\n",
            "D: -0.6911875009536743\n",
            "GP: 0.1253623068332672\n",
            "Gradient norm: 0.9869522452354431\n",
            "G: -0.11443336308002472\n",
            "Iteration 201\n",
            "D: -0.7176018357276917\n",
            "GP: 0.10208038985729218\n",
            "Gradient norm: 0.9794491529464722\n",
            "G: -0.10730243474245071\n",
            "Iteration 251\n",
            "D: -0.7101187705993652\n",
            "GP: 0.08880572021007538\n",
            "Gradient norm: 0.9896335005760193\n",
            "G: -0.09174633026123047\n",
            "Iteration 301\n",
            "D: -0.7355891466140747\n",
            "GP: 0.06401624530553818\n",
            "Gradient norm: 0.9941205978393555\n",
            "G: -0.09675578027963638\n",
            "Iteration 351\n",
            "D: -0.7149724960327148\n",
            "GP: 0.06607621908187866\n",
            "Gradient norm: 1.0004475116729736\n",
            "G: -0.10416211187839508\n",
            "Iteration 401\n",
            "D: -0.6312731504440308\n",
            "GP: 0.10016797482967377\n",
            "Gradient norm: 1.000037431716919\n",
            "G: -0.10836566239595413\n",
            "Iteration 451\n",
            "D: -0.6885395050048828\n",
            "GP: 0.08203592151403427\n",
            "Gradient norm: 0.9580016732215881\n",
            "G: -0.12150019407272339\n",
            "Iteration 501\n",
            "D: -0.6631061434745789\n",
            "GP: 0.114268958568573\n",
            "Gradient norm: 0.9912856817245483\n",
            "G: -0.10154417157173157\n",
            "Iteration 551\n",
            "D: -0.6802534461021423\n",
            "GP: 0.09916150569915771\n",
            "Gradient norm: 0.9729830026626587\n",
            "G: -0.10629651695489883\n",
            "Iteration 601\n",
            "D: -0.7196364402770996\n",
            "GP: 0.07676391303539276\n",
            "Gradient norm: 0.985206127166748\n",
            "G: -0.11136813461780548\n",
            "Iteration 651\n",
            "D: -0.705272376537323\n",
            "GP: 0.07850784063339233\n",
            "Gradient norm: 0.9761309027671814\n",
            "G: -0.10006498545408249\n",
            "Iteration 701\n",
            "D: -0.7503554224967957\n",
            "GP: 0.037813857197761536\n",
            "Gradient norm: 0.983237087726593\n",
            "G: -0.10417033731937408\n",
            "Iteration 751\n",
            "D: -0.7252610325813293\n",
            "GP: 0.06305386871099472\n",
            "Gradient norm: 0.9912073016166687\n",
            "G: -0.08845251798629761\n",
            "Iteration 801\n",
            "D: -0.7168595790863037\n",
            "GP: 0.08556438982486725\n",
            "Gradient norm: 0.9758129119873047\n",
            "G: -0.10077308118343353\n",
            "Iteration 851\n",
            "D: -0.7508420944213867\n",
            "GP: 0.039246007800102234\n",
            "Gradient norm: 0.9952273964881897\n",
            "G: -0.09964900463819504\n",
            "Iteration 901\n",
            "D: -0.6914756298065186\n",
            "GP: 0.08600059151649475\n",
            "Gradient norm: 0.9788649082183838\n",
            "G: -0.09380793571472168\n",
            "\n",
            "Epoch 13\n",
            "Iteration 1\n",
            "D: -0.7086816430091858\n",
            "GP: 0.06664030998945236\n",
            "Gradient norm: 0.9794474840164185\n",
            "G: -0.11546429246664047\n",
            "Iteration 51\n",
            "D: -0.7027021050453186\n",
            "GP: 0.0825371965765953\n",
            "Gradient norm: 0.9956921935081482\n",
            "G: -0.11206666380167007\n",
            "Iteration 101\n",
            "D: -0.753341019153595\n",
            "GP: 0.048861727118492126\n",
            "Gradient norm: 1.002449870109558\n",
            "G: -0.10993726551532745\n",
            "Iteration 151\n",
            "D: -0.6708199977874756\n",
            "GP: 0.13113296031951904\n",
            "Gradient norm: 0.9796784520149231\n",
            "G: -0.1102328896522522\n",
            "Iteration 201\n",
            "D: -0.6802557110786438\n",
            "GP: 0.12945501506328583\n",
            "Gradient norm: 0.9924789071083069\n",
            "G: -0.10275551676750183\n",
            "Iteration 251\n",
            "D: -0.6559175848960876\n",
            "GP: 0.11905748397111893\n",
            "Gradient norm: 1.0190057754516602\n",
            "G: -0.1133936196565628\n",
            "Iteration 301\n",
            "D: -0.7273785471916199\n",
            "GP: 0.06211775913834572\n",
            "Gradient norm: 0.9907042980194092\n",
            "G: -0.106369748711586\n",
            "Iteration 351\n",
            "D: -0.6858487129211426\n",
            "GP: 0.08887755870819092\n",
            "Gradient norm: 0.9503554105758667\n",
            "G: -0.11988181620836258\n",
            "Iteration 401\n",
            "D: -0.6880891919136047\n",
            "GP: 0.1138954758644104\n",
            "Gradient norm: 0.9915072917938232\n",
            "G: -0.10511668026447296\n",
            "Iteration 451\n",
            "D: -0.7107024192810059\n",
            "GP: 0.08416429162025452\n",
            "Gradient norm: 0.9909381866455078\n",
            "G: -0.0875510722398758\n",
            "Iteration 501\n",
            "D: -0.6990401744842529\n",
            "GP: 0.09572755545377731\n",
            "Gradient norm: 1.0058485269546509\n",
            "G: -0.09757557511329651\n",
            "Iteration 551\n",
            "D: -0.7630619406700134\n",
            "GP: 0.05816872417926788\n",
            "Gradient norm: 1.006070852279663\n",
            "G: -0.08919490873813629\n",
            "Iteration 601\n",
            "D: -0.7567036151885986\n",
            "GP: 0.07217142730951309\n",
            "Gradient norm: 0.9665630459785461\n",
            "G: -0.08728361129760742\n",
            "Iteration 651\n",
            "D: -0.7429552674293518\n",
            "GP: 0.05718238651752472\n",
            "Gradient norm: 0.9811708927154541\n",
            "G: -0.0840744748711586\n",
            "Iteration 701\n",
            "D: -0.7643374800682068\n",
            "GP: 0.05095607042312622\n",
            "Gradient norm: 0.9922956228256226\n",
            "G: -0.09057720005512238\n",
            "Iteration 751\n",
            "D: -0.7481277585029602\n",
            "GP: 0.06713026016950607\n",
            "Gradient norm: 0.997474193572998\n",
            "G: -0.08659729361534119\n",
            "Iteration 801\n",
            "D: -0.772088885307312\n",
            "GP: 0.047588467597961426\n",
            "Gradient norm: 1.0147901773452759\n",
            "G: -0.08531474322080612\n",
            "Iteration 851\n",
            "D: -0.7870994210243225\n",
            "GP: 0.04390659183263779\n",
            "Gradient norm: 0.9878519773483276\n",
            "G: -0.09553657472133636\n",
            "Iteration 901\n",
            "D: -0.7445686459541321\n",
            "GP: 0.05554680526256561\n",
            "Gradient norm: 0.9912084341049194\n",
            "G: -0.08739103376865387\n",
            "\n",
            "Epoch 14\n",
            "Iteration 1\n",
            "D: -0.775654673576355\n",
            "GP: 0.046378232538700104\n",
            "Gradient norm: 0.9877059459686279\n",
            "G: -0.07723219692707062\n",
            "Iteration 51\n",
            "D: -0.7531560063362122\n",
            "GP: 0.05242779105901718\n",
            "Gradient norm: 1.0083359479904175\n",
            "G: -0.08283911645412445\n",
            "Iteration 101\n",
            "D: -0.7832086682319641\n",
            "GP: 0.047881435602903366\n",
            "Gradient norm: 0.9853317737579346\n",
            "G: -0.07978881895542145\n",
            "Iteration 151\n",
            "D: -0.7779498100280762\n",
            "GP: 0.04290412366390228\n",
            "Gradient norm: 0.9733141660690308\n",
            "G: -0.08140714466571808\n",
            "Iteration 201\n",
            "D: -0.8070183992385864\n",
            "GP: 0.03321763128042221\n",
            "Gradient norm: 0.9949207305908203\n",
            "G: -0.08828367292881012\n",
            "Iteration 251\n",
            "D: -0.7890150547027588\n",
            "GP: 0.06814731657505035\n",
            "Gradient norm: 0.9863767027854919\n",
            "G: -0.07592502236366272\n",
            "Iteration 301\n",
            "D: -0.7681413292884827\n",
            "GP: 0.04682248458266258\n",
            "Gradient norm: 0.9935030341148376\n",
            "G: -0.09615783393383026\n",
            "Iteration 351\n",
            "D: -0.7380654811859131\n",
            "GP: 0.08802278339862823\n",
            "Gradient norm: 1.0101031064987183\n",
            "G: -0.09980998933315277\n",
            "Iteration 401\n",
            "D: -0.7551435828208923\n",
            "GP: 0.09050816297531128\n",
            "Gradient norm: 1.010908842086792\n",
            "G: -0.0843329131603241\n",
            "Iteration 451\n",
            "D: -0.7604323625564575\n",
            "GP: 0.05129659175872803\n",
            "Gradient norm: 0.9940313100814819\n",
            "G: -0.09634165465831757\n",
            "Iteration 501\n",
            "D: -0.7632349133491516\n",
            "GP: 0.04384049028158188\n",
            "Gradient norm: 1.0030674934387207\n",
            "G: -0.0925157368183136\n",
            "Iteration 551\n",
            "D: -0.7629781365394592\n",
            "GP: 0.07196079194545746\n",
            "Gradient norm: 0.9842554330825806\n",
            "G: -0.08818352222442627\n",
            "Iteration 601\n",
            "D: -0.7830315828323364\n",
            "GP: 0.04817510396242142\n",
            "Gradient norm: 0.972909688949585\n",
            "G: -0.0936204120516777\n",
            "Iteration 651\n",
            "D: -0.7757288813591003\n",
            "GP: 0.07273714244365692\n",
            "Gradient norm: 0.9693791270256042\n",
            "G: -0.08750905841588974\n",
            "Iteration 701\n",
            "D: -0.7315558195114136\n",
            "GP: 0.11234692484140396\n",
            "Gradient norm: 0.9655051827430725\n",
            "G: -0.08954805135726929\n",
            "Iteration 751\n",
            "D: -0.7334190607070923\n",
            "GP: 0.0774710550904274\n",
            "Gradient norm: 1.0152103900909424\n",
            "G: -0.10641983151435852\n",
            "Iteration 801\n",
            "D: -0.7014279365539551\n",
            "GP: 0.12842902541160583\n",
            "Gradient norm: 0.9842240810394287\n",
            "G: -0.08190040290355682\n",
            "Iteration 851\n",
            "D: -0.761408269405365\n",
            "GP: 0.056419339030981064\n",
            "Gradient norm: 0.9941028356552124\n",
            "G: -0.10257171094417572\n",
            "Iteration 901\n",
            "D: -0.7677016258239746\n",
            "GP: 0.04634779691696167\n",
            "Gradient norm: 0.9900064468383789\n",
            "G: -0.10777105391025543\n",
            "\n",
            "Epoch 15\n",
            "Iteration 1\n",
            "D: -0.7265021204948425\n",
            "GP: 0.11692263185977936\n",
            "Gradient norm: 1.0191093683242798\n",
            "G: -0.09416885673999786\n",
            "Iteration 51\n",
            "D: -0.6996995210647583\n",
            "GP: 0.11627774685621262\n",
            "Gradient norm: 0.9911271333694458\n",
            "G: -0.09895336627960205\n",
            "Iteration 101\n",
            "D: -0.7613608837127686\n",
            "GP: 0.06318480521440506\n",
            "Gradient norm: 0.9815694093704224\n",
            "G: -0.09958982467651367\n",
            "Iteration 151\n",
            "D: -0.767251193523407\n",
            "GP: 0.0796249657869339\n",
            "Gradient norm: 0.9849470853805542\n",
            "G: -0.08557417243719101\n",
            "Iteration 201\n",
            "D: -0.7896310687065125\n",
            "GP: 0.06122495234012604\n",
            "Gradient norm: 0.9808294773101807\n",
            "G: -0.08997005224227905\n",
            "Iteration 251\n",
            "D: -0.7375883460044861\n",
            "GP: 0.08741359412670135\n",
            "Gradient norm: 1.0046626329421997\n",
            "G: -0.06989340484142303\n",
            "Iteration 301\n",
            "D: -0.7710652947425842\n",
            "GP: 0.05106966942548752\n",
            "Gradient norm: 1.0059235095977783\n",
            "G: -0.07778813689947128\n",
            "Iteration 351\n",
            "D: -0.7179495692253113\n",
            "GP: 0.09317225217819214\n",
            "Gradient norm: 1.0070385932922363\n",
            "G: -0.09605773538351059\n",
            "Iteration 401\n",
            "D: -0.7339373826980591\n",
            "GP: 0.09726081043481827\n",
            "Gradient norm: 1.0072221755981445\n",
            "G: -0.07943713665008545\n",
            "Iteration 451\n",
            "D: -0.7927554249763489\n",
            "GP: 0.07172967493534088\n",
            "Gradient norm: 0.9975950121879578\n",
            "G: -0.07441513985395432\n",
            "Iteration 501\n",
            "D: -0.798147976398468\n",
            "GP: 0.0650075152516365\n",
            "Gradient norm: 0.9649242758750916\n",
            "G: -0.06752696633338928\n",
            "Iteration 551\n",
            "D: -0.787539541721344\n",
            "GP: 0.06405871361494064\n",
            "Gradient norm: 0.9782319068908691\n",
            "G: -0.07815820723772049\n",
            "Iteration 601\n",
            "D: -0.8281986117362976\n",
            "GP: 0.039254359900951385\n",
            "Gradient norm: 0.9961059093475342\n",
            "G: -0.06997016072273254\n",
            "Iteration 651\n",
            "D: -0.7123435735702515\n",
            "GP: 0.08328719437122345\n",
            "Gradient norm: 0.9971464276313782\n",
            "G: -0.08821798861026764\n",
            "Iteration 701\n",
            "D: -0.7537851929664612\n",
            "GP: 0.05414344370365143\n",
            "Gradient norm: 0.9879953265190125\n",
            "G: -0.07792495936155319\n",
            "Iteration 751\n",
            "D: -0.7634201049804688\n",
            "GP: 0.07079195231199265\n",
            "Gradient norm: 1.0106463432312012\n",
            "G: -0.07280007004737854\n",
            "Iteration 801\n",
            "D: -0.7450753450393677\n",
            "GP: 0.07949104905128479\n",
            "Gradient norm: 1.0298397541046143\n",
            "G: -0.06586302816867828\n",
            "Iteration 851\n",
            "D: -0.7412832975387573\n",
            "GP: 0.08849368989467621\n",
            "Gradient norm: 0.9807205200195312\n",
            "G: -0.08814844489097595\n",
            "Iteration 901\n",
            "D: -0.6812326908111572\n",
            "GP: 0.11399967968463898\n",
            "Gradient norm: 0.9753426313400269\n",
            "G: -0.07795222103595734\n",
            "\n",
            "Epoch 16\n",
            "Iteration 1\n",
            "D: -0.687210202217102\n",
            "GP: 0.12756285071372986\n",
            "Gradient norm: 0.9475036263465881\n",
            "G: -0.09960084408521652\n",
            "Iteration 51\n",
            "D: -0.7933182716369629\n",
            "GP: 0.03253099322319031\n",
            "Gradient norm: 1.0033761262893677\n",
            "G: -0.07409939169883728\n",
            "Iteration 101\n",
            "D: -0.7956809997558594\n",
            "GP: 0.07242218405008316\n",
            "Gradient norm: 0.991421639919281\n",
            "G: -0.07380200922489166\n",
            "Iteration 151\n",
            "D: -0.7961941957473755\n",
            "GP: 0.040725402534008026\n",
            "Gradient norm: 0.9928359389305115\n",
            "G: -0.0794675350189209\n",
            "Iteration 201\n",
            "D: -0.7938886880874634\n",
            "GP: 0.05003558099269867\n",
            "Gradient norm: 0.9980980157852173\n",
            "G: -0.07873190939426422\n",
            "Iteration 251\n",
            "D: -0.7934204936027527\n",
            "GP: 0.04668097198009491\n",
            "Gradient norm: 0.9977162480354309\n",
            "G: -0.08005894720554352\n",
            "Iteration 301\n",
            "D: -0.8321768045425415\n",
            "GP: 0.059374600648880005\n",
            "Gradient norm: 0.9662023186683655\n",
            "G: -0.058383408933877945\n",
            "Iteration 351\n",
            "D: -0.7779573798179626\n",
            "GP: 0.06779342889785767\n",
            "Gradient norm: 0.9864576458930969\n",
            "G: -0.07602961361408234\n",
            "Iteration 401\n",
            "D: -0.7621926069259644\n",
            "GP: 0.06175043433904648\n",
            "Gradient norm: 0.9995204210281372\n",
            "G: -0.08520003408193588\n",
            "Iteration 451\n",
            "D: -0.8030800223350525\n",
            "GP: 0.03848513588309288\n",
            "Gradient norm: 0.9975767135620117\n",
            "G: -0.07624170184135437\n",
            "Iteration 501\n",
            "D: -0.7919676899909973\n",
            "GP: 0.045734528452157974\n",
            "Gradient norm: 0.9935026168823242\n",
            "G: -0.07026232779026031\n",
            "Iteration 551\n",
            "D: -0.7592481970787048\n",
            "GP: 0.054658494889736176\n",
            "Gradient norm: 0.9929922819137573\n",
            "G: -0.06275399774312973\n",
            "Iteration 601\n",
            "D: -0.6703728437423706\n",
            "GP: 0.0916949212551117\n",
            "Gradient norm: 0.9898260831832886\n",
            "G: -0.08673493564128876\n",
            "Iteration 651\n",
            "D: -0.7593638300895691\n",
            "GP: 0.07479361444711685\n",
            "Gradient norm: 0.9853537082672119\n",
            "G: -0.09454759955406189\n",
            "Iteration 701\n",
            "D: -0.7746272087097168\n",
            "GP: 0.037006329745054245\n",
            "Gradient norm: 0.990917444229126\n",
            "G: -0.09274393320083618\n",
            "Iteration 751\n",
            "D: -0.7312998175621033\n",
            "GP: 0.0803900957107544\n",
            "Gradient norm: 0.9740082025527954\n",
            "G: -0.09348699450492859\n",
            "Iteration 801\n",
            "D: -0.7472060918807983\n",
            "GP: 0.08928847312927246\n",
            "Gradient norm: 1.004083275794983\n",
            "G: -0.0868215262889862\n",
            "Iteration 851\n",
            "D: -0.8040443658828735\n",
            "GP: 0.025516901165246964\n",
            "Gradient norm: 0.9822729825973511\n",
            "G: -0.07668069750070572\n",
            "Iteration 901\n",
            "D: -0.7609502077102661\n",
            "GP: 0.061167843639850616\n",
            "Gradient norm: 0.9884379506111145\n",
            "G: -0.09223766624927521\n",
            "\n",
            "Epoch 17\n",
            "Iteration 1\n",
            "D: -0.7589377164840698\n",
            "GP: 0.058449018746614456\n",
            "Gradient norm: 0.9875341057777405\n",
            "G: -0.07803698629140854\n",
            "Iteration 51\n",
            "D: -0.8006566166877747\n",
            "GP: 0.060714781284332275\n",
            "Gradient norm: 1.000661849975586\n",
            "G: -0.07739517837762833\n",
            "Iteration 101\n",
            "D: -0.7596068382263184\n",
            "GP: 0.07653674483299255\n",
            "Gradient norm: 0.973450779914856\n",
            "G: -0.07408259809017181\n",
            "Iteration 151\n",
            "D: -0.7594820857048035\n",
            "GP: 0.09557720273733139\n",
            "Gradient norm: 0.9723860025405884\n",
            "G: -0.06786146759986877\n",
            "Iteration 201\n",
            "D: -0.8040165305137634\n",
            "GP: 0.049722492694854736\n",
            "Gradient norm: 0.9905238747596741\n",
            "G: -0.07943565398454666\n",
            "Iteration 251\n",
            "D: -0.6854499578475952\n",
            "GP: 0.1236826553940773\n",
            "Gradient norm: 1.0062229633331299\n",
            "G: -0.09379398077726364\n",
            "Iteration 301\n",
            "D: -0.5891202688217163\n",
            "GP: 0.12962636351585388\n",
            "Gradient norm: 0.9648363590240479\n",
            "G: -0.12683622539043427\n",
            "Iteration 351\n",
            "D: -0.6837124824523926\n",
            "GP: 0.06142977625131607\n",
            "Gradient norm: 0.9979411363601685\n",
            "G: -0.12142986804246902\n",
            "Iteration 401\n",
            "D: -0.7042996883392334\n",
            "GP: 0.0649440586566925\n",
            "Gradient norm: 0.9890520572662354\n",
            "G: -0.08785897493362427\n",
            "Iteration 451\n",
            "D: -0.6714821457862854\n",
            "GP: 0.11465615034103394\n",
            "Gradient norm: 0.9740129709243774\n",
            "G: -0.10586105287075043\n",
            "Iteration 501\n",
            "D: -0.7241455316543579\n",
            "GP: 0.06089114397764206\n",
            "Gradient norm: 0.9921683669090271\n",
            "G: -0.11259113252162933\n",
            "Iteration 551\n",
            "D: -0.7233741879463196\n",
            "GP: 0.07911117374897003\n",
            "Gradient norm: 1.0057237148284912\n",
            "G: -0.08968722820281982\n",
            "Iteration 601\n",
            "D: -0.686680793762207\n",
            "GP: 0.11649468541145325\n",
            "Gradient norm: 0.9668803215026855\n",
            "G: -0.09414315968751907\n",
            "Iteration 651\n",
            "D: -0.7443711757659912\n",
            "GP: 0.09667087346315384\n",
            "Gradient norm: 0.9778287410736084\n",
            "G: -0.10314148664474487\n",
            "Iteration 701\n",
            "D: -0.7275824546813965\n",
            "GP: 0.11602529883384705\n",
            "Gradient norm: 0.9951635599136353\n",
            "G: -0.09519574046134949\n",
            "Iteration 751\n",
            "D: -0.711456298828125\n",
            "GP: 0.06872563064098358\n",
            "Gradient norm: 1.0030103921890259\n",
            "G: -0.10851282626390457\n",
            "Iteration 801\n",
            "D: -0.7233788967132568\n",
            "GP: 0.08037343621253967\n",
            "Gradient norm: 0.9762718081474304\n",
            "G: -0.11182905733585358\n",
            "Iteration 851\n",
            "D: -0.6839527487754822\n",
            "GP: 0.09667448699474335\n",
            "Gradient norm: 1.0005559921264648\n",
            "G: -0.0979347825050354\n",
            "Iteration 901\n",
            "D: -0.7338998317718506\n",
            "GP: 0.04958302155137062\n",
            "Gradient norm: 1.0028895139694214\n",
            "G: -0.10718931257724762\n",
            "\n",
            "Epoch 18\n",
            "Iteration 1\n",
            "D: -0.6608928442001343\n",
            "GP: 0.09823336452245712\n",
            "Gradient norm: 0.9723970890045166\n",
            "G: -0.1167280375957489\n",
            "Iteration 51\n",
            "D: -0.5823808908462524\n",
            "GP: 0.06407954543828964\n",
            "Gradient norm: 0.9727466106414795\n",
            "G: -0.18014243245124817\n",
            "Iteration 101\n",
            "D: -0.5548045635223389\n",
            "GP: 0.07690975069999695\n",
            "Gradient norm: 0.9963386058807373\n",
            "G: -0.18043123185634613\n",
            "Iteration 151\n",
            "D: -0.5725511312484741\n",
            "GP: 0.10191535949707031\n",
            "Gradient norm: 0.9874213933944702\n",
            "G: -0.15626952052116394\n",
            "Iteration 201\n",
            "D: -0.6129860877990723\n",
            "GP: 0.077848419547081\n",
            "Gradient norm: 0.9901105165481567\n",
            "G: -0.15363621711730957\n",
            "Iteration 251\n",
            "D: -0.6388629674911499\n",
            "GP: 0.08510386943817139\n",
            "Gradient norm: 0.9737449288368225\n",
            "G: -0.15561649203300476\n",
            "Iteration 301\n",
            "D: -0.6921124458312988\n",
            "GP: 0.10563896596431732\n",
            "Gradient norm: 0.9955301284790039\n",
            "G: -0.12794944643974304\n",
            "Iteration 351\n",
            "D: -0.6733914017677307\n",
            "GP: 0.04738135263323784\n",
            "Gradient norm: 0.9776618480682373\n",
            "G: -0.16640549898147583\n",
            "Iteration 401\n",
            "D: -0.4653956890106201\n",
            "GP: 0.16939914226531982\n",
            "Gradient norm: 0.981285572052002\n",
            "G: -0.18929722905158997\n",
            "Iteration 451\n",
            "D: -0.5552259683609009\n",
            "GP: 0.07976016402244568\n",
            "Gradient norm: 0.9953333139419556\n",
            "G: -0.19110605120658875\n",
            "Iteration 501\n",
            "D: -0.6260570287704468\n",
            "GP: 0.0637647956609726\n",
            "Gradient norm: 0.9882746934890747\n",
            "G: -0.15784627199172974\n",
            "Iteration 551\n",
            "D: -0.6758641600608826\n",
            "GP: 0.06986955553293228\n",
            "Gradient norm: 0.9817335605621338\n",
            "G: -0.13102774322032928\n",
            "Iteration 601\n",
            "D: -0.6354137659072876\n",
            "GP: 0.08725867420434952\n",
            "Gradient norm: 0.9852160811424255\n",
            "G: -0.13207176327705383\n",
            "Iteration 651\n",
            "D: -0.591992199420929\n",
            "GP: 0.10346803814172745\n",
            "Gradient norm: 0.9757561683654785\n",
            "G: -0.1706009954214096\n",
            "Iteration 701\n",
            "D: -0.5962533950805664\n",
            "GP: 0.1110585406422615\n",
            "Gradient norm: 0.9752616286277771\n",
            "G: -0.1535409688949585\n",
            "Iteration 751\n",
            "D: -0.6704562902450562\n",
            "GP: 0.06321693956851959\n",
            "Gradient norm: 1.0045619010925293\n",
            "G: -0.12105199694633484\n",
            "Iteration 801\n",
            "D: -0.6595534682273865\n",
            "GP: 0.08720988035202026\n",
            "Gradient norm: 1.0028269290924072\n",
            "G: -0.12717022001743317\n",
            "Iteration 851\n",
            "D: -0.589723527431488\n",
            "GP: 0.06451849639415741\n",
            "Gradient norm: 0.9969077110290527\n",
            "G: -0.15243366360664368\n",
            "Iteration 901\n",
            "D: -0.4036872684955597\n",
            "GP: 0.05462689325213432\n",
            "Gradient norm: 0.9873269200325012\n",
            "G: -0.2733752727508545\n",
            "\n",
            "Epoch 19\n",
            "Iteration 1\n",
            "D: -0.4809662699699402\n",
            "GP: 0.07867150753736496\n",
            "Gradient norm: 0.994936466217041\n",
            "G: -0.29780322313308716\n",
            "Iteration 51\n",
            "D: -0.5812502503395081\n",
            "GP: 0.07870824635028839\n",
            "Gradient norm: 1.0064969062805176\n",
            "G: -0.21925237774848938\n",
            "Iteration 101\n",
            "D: -0.6028576493263245\n",
            "GP: 0.0620776005089283\n",
            "Gradient norm: 0.9875024557113647\n",
            "G: -0.1609414517879486\n",
            "Iteration 151\n",
            "D: -0.5747690200805664\n",
            "GP: 0.11183429509401321\n",
            "Gradient norm: 0.9889187812805176\n",
            "G: -0.1674148440361023\n",
            "Iteration 201\n",
            "D: -0.5668935179710388\n",
            "GP: 0.06293565034866333\n",
            "Gradient norm: 0.9967005252838135\n",
            "G: -0.17704659700393677\n",
            "Iteration 251\n",
            "D: -0.4889400005340576\n",
            "GP: 0.06862546503543854\n",
            "Gradient norm: 0.9555450677871704\n",
            "G: -0.2055712640285492\n",
            "Iteration 301\n",
            "D: -0.5494134426116943\n",
            "GP: 0.08521318435668945\n",
            "Gradient norm: 0.9762955904006958\n",
            "G: -0.18724873661994934\n",
            "Iteration 351\n",
            "D: -0.6094468832015991\n",
            "GP: 0.10203161090612411\n",
            "Gradient norm: 0.9937444925308228\n",
            "G: -0.15934918820858002\n",
            "Iteration 401\n",
            "D: -0.6156472563743591\n",
            "GP: 0.08629636466503143\n",
            "Gradient norm: 1.001363754272461\n",
            "G: -0.14129069447517395\n",
            "Iteration 451\n",
            "D: -0.5967022776603699\n",
            "GP: 0.10044064372777939\n",
            "Gradient norm: 0.9835437536239624\n",
            "G: -0.15016667544841766\n",
            "Iteration 501\n",
            "D: -0.594028890132904\n",
            "GP: 0.07513593137264252\n",
            "Gradient norm: 0.9883830547332764\n",
            "G: -0.14742854237556458\n",
            "Iteration 551\n",
            "D: -0.5212202072143555\n",
            "GP: 0.09527694433927536\n",
            "Gradient norm: 1.00404691696167\n",
            "G: -0.15701976418495178\n",
            "Iteration 601\n",
            "D: -0.5500233173370361\n",
            "GP: 0.08545804768800735\n",
            "Gradient norm: 1.0022549629211426\n",
            "G: -0.12339743971824646\n",
            "Iteration 651\n",
            "D: -0.48665836453437805\n",
            "GP: 0.17386814951896667\n",
            "Gradient norm: 0.9613549709320068\n",
            "G: -0.12181290239095688\n",
            "Iteration 701\n",
            "D: -0.624893844127655\n",
            "GP: 0.13797320425510406\n",
            "Gradient norm: 0.986190676689148\n",
            "G: -0.09032822400331497\n",
            "Iteration 751\n",
            "D: -0.6871625781059265\n",
            "GP: 0.07011178880929947\n",
            "Gradient norm: 1.0099313259124756\n",
            "G: -0.11494434624910355\n",
            "Iteration 801\n",
            "D: -0.7111853361129761\n",
            "GP: 0.07008467614650726\n",
            "Gradient norm: 1.0122158527374268\n",
            "G: -0.09204602241516113\n",
            "Iteration 851\n",
            "D: -0.6450713276863098\n",
            "GP: 0.09379308670759201\n",
            "Gradient norm: 0.9815187454223633\n",
            "G: -0.10209782421588898\n",
            "Iteration 901\n",
            "D: -0.543724000453949\n",
            "GP: 0.08529897779226303\n",
            "Gradient norm: 0.9910426139831543\n",
            "G: -0.16613206267356873\n",
            "\n",
            "Epoch 20\n",
            "Iteration 1\n",
            "D: -0.5145919322967529\n",
            "GP: 0.06117090955376625\n",
            "Gradient norm: 0.9889534711837769\n",
            "G: -0.23720954358577728\n",
            "Iteration 51\n",
            "D: -0.4933534860610962\n",
            "GP: 0.09897178411483765\n",
            "Gradient norm: 1.020268201828003\n",
            "G: -0.21555331349372864\n",
            "Iteration 101\n",
            "D: -0.6423984169960022\n",
            "GP: 0.08284702152013779\n",
            "Gradient norm: 1.0092520713806152\n",
            "G: -0.13596521317958832\n",
            "Iteration 151\n",
            "D: -0.5822422504425049\n",
            "GP: 0.1577141135931015\n",
            "Gradient norm: 0.993236780166626\n",
            "G: -0.12786749005317688\n",
            "Iteration 201\n",
            "D: -0.6584570407867432\n",
            "GP: 0.0641089528799057\n",
            "Gradient norm: 1.0083467960357666\n",
            "G: -0.15296319127082825\n",
            "Iteration 251\n",
            "D: -0.4671455919742584\n",
            "GP: 0.18058446049690247\n",
            "Gradient norm: 1.0066299438476562\n",
            "G: -0.17883379757404327\n",
            "Iteration 301\n",
            "D: -0.615851640701294\n",
            "GP: 0.07154644280672073\n",
            "Gradient norm: 0.9853178858757019\n",
            "G: -0.16928362846374512\n",
            "Iteration 351\n",
            "D: -0.533078670501709\n",
            "GP: 0.0887928158044815\n",
            "Gradient norm: 0.9916355609893799\n",
            "G: -0.17466136813163757\n",
            "Iteration 401\n",
            "D: -0.5027031302452087\n",
            "GP: 0.07709117233753204\n",
            "Gradient norm: 0.9965095520019531\n",
            "G: -0.221284419298172\n",
            "Iteration 451\n",
            "D: -0.4525819718837738\n",
            "GP: 0.06943605095148087\n",
            "Gradient norm: 0.9829851388931274\n",
            "G: -0.23884496092796326\n",
            "Iteration 501\n",
            "D: -0.5071537494659424\n",
            "GP: 0.05961984023451805\n",
            "Gradient norm: 0.9858345985412598\n",
            "G: -0.2005155384540558\n",
            "Iteration 551\n",
            "D: -0.5990533828735352\n",
            "GP: 0.06562390178442001\n",
            "Gradient norm: 0.9813838601112366\n",
            "G: -0.14685821533203125\n",
            "Iteration 601\n",
            "D: -0.6383680105209351\n",
            "GP: 0.05857968330383301\n",
            "Gradient norm: 0.9835559725761414\n",
            "G: -0.1566098928451538\n",
            "Iteration 651\n",
            "D: -0.6771374940872192\n",
            "GP: 0.07064388692378998\n",
            "Gradient norm: 0.9808671474456787\n",
            "G: -0.12799637019634247\n",
            "Iteration 701\n",
            "D: -0.6350468993186951\n",
            "GP: 0.1180078461766243\n",
            "Gradient norm: 0.9718794226646423\n",
            "G: -0.12829463183879852\n",
            "Iteration 751\n",
            "D: -0.6370824575424194\n",
            "GP: 0.07871487736701965\n",
            "Gradient norm: 0.9913973808288574\n",
            "G: -0.13062211871147156\n",
            "Iteration 801\n",
            "D: -0.6959084272384644\n",
            "GP: 0.055669672787189484\n",
            "Gradient norm: 1.0139689445495605\n",
            "G: -0.11137917637825012\n",
            "Iteration 851\n",
            "D: -0.6998036503791809\n",
            "GP: 0.05884707346558571\n",
            "Gradient norm: 0.9847477674484253\n",
            "G: -0.10091564804315567\n",
            "Iteration 901\n",
            "D: -0.6134670972824097\n",
            "GP: 0.118642657995224\n",
            "Gradient norm: 0.9780531525611877\n",
            "G: -0.1130450963973999\n",
            "\n",
            "Epoch 21\n",
            "Iteration 1\n",
            "D: -0.6519560217857361\n",
            "GP: 0.05594269186258316\n",
            "Gradient norm: 1.0248160362243652\n",
            "G: -0.15479665994644165\n",
            "Iteration 51\n",
            "D: -0.5728979110717773\n",
            "GP: 0.07387332618236542\n",
            "Gradient norm: 1.0034925937652588\n",
            "G: -0.17593608796596527\n",
            "Iteration 101\n",
            "D: -0.5001598596572876\n",
            "GP: 0.19264638423919678\n",
            "Gradient norm: 1.004928469657898\n",
            "G: -0.15069788694381714\n",
            "Iteration 151\n",
            "D: -0.5640351176261902\n",
            "GP: 0.10233752429485321\n",
            "Gradient norm: 1.0055968761444092\n",
            "G: -0.1609617918729782\n",
            "Iteration 201\n",
            "D: -0.5957759618759155\n",
            "GP: 0.0967196375131607\n",
            "Gradient norm: 1.0043749809265137\n",
            "G: -0.1732603907585144\n",
            "Iteration 251\n",
            "D: -0.6600088477134705\n",
            "GP: 0.0786997526884079\n",
            "Gradient norm: 0.9842050671577454\n",
            "G: -0.13899239897727966\n",
            "Iteration 301\n",
            "D: -0.7097270488739014\n",
            "GP: 0.07021301239728928\n",
            "Gradient norm: 0.9920626282691956\n",
            "G: -0.1010853499174118\n",
            "Iteration 351\n",
            "D: -0.6344351768493652\n",
            "GP: 0.11614860594272614\n",
            "Gradient norm: 0.9690184593200684\n",
            "G: -0.11924527585506439\n",
            "Iteration 401\n",
            "D: -0.6698892712593079\n",
            "GP: 0.06227046623826027\n",
            "Gradient norm: 0.9803731441497803\n",
            "G: -0.11582545191049576\n",
            "Iteration 451\n",
            "D: -0.6478192806243896\n",
            "GP: 0.10341314971446991\n",
            "Gradient norm: 0.9792530536651611\n",
            "G: -0.09722177684307098\n",
            "Iteration 501\n",
            "D: -0.63751620054245\n",
            "GP: 0.11576763540506363\n",
            "Gradient norm: 0.9837753772735596\n",
            "G: -0.1099831834435463\n",
            "Iteration 551\n",
            "D: -0.6301652789115906\n",
            "GP: 0.09716099500656128\n",
            "Gradient norm: 1.0181918144226074\n",
            "G: -0.10215730965137482\n",
            "Iteration 601\n",
            "D: -0.5845907330513\n",
            "GP: 0.13336056470870972\n",
            "Gradient norm: 1.0166441202163696\n",
            "G: -0.09144671261310577\n",
            "Iteration 651\n",
            "D: -0.7446552515029907\n",
            "GP: 0.04447280615568161\n",
            "Gradient norm: 0.9852714538574219\n",
            "G: -0.0798320472240448\n",
            "Iteration 701\n",
            "D: -0.7677605152130127\n",
            "GP: 0.04136953875422478\n",
            "Gradient norm: 0.9903702735900879\n",
            "G: -0.07008250057697296\n",
            "Iteration 751\n",
            "D: -0.6946274638175964\n",
            "GP: 0.08816832304000854\n",
            "Gradient norm: 0.9785512089729309\n",
            "G: -0.05431552603840828\n",
            "Iteration 801\n",
            "D: -0.7094080448150635\n",
            "GP: 0.04282286390662193\n",
            "Gradient norm: 1.0056345462799072\n",
            "G: -0.08087170124053955\n",
            "Iteration 851\n",
            "D: -0.6369000673294067\n",
            "GP: 0.08768785744905472\n",
            "Gradient norm: 0.9976685643196106\n",
            "G: -0.08692523092031479\n",
            "Iteration 901\n",
            "D: -0.5837857127189636\n",
            "GP: 0.06957276910543442\n",
            "Gradient norm: 0.9909276962280273\n",
            "G: -0.11881870031356812\n",
            "\n",
            "Epoch 22\n",
            "Iteration 1\n",
            "D: -0.554803192615509\n",
            "GP: 0.05596223846077919\n",
            "Gradient norm: 0.994350790977478\n",
            "G: -0.1794275939464569\n",
            "Iteration 51\n",
            "D: -0.5474138855934143\n",
            "GP: 0.056468453258275986\n",
            "Gradient norm: 0.9743654727935791\n",
            "G: -0.182142436504364\n",
            "Iteration 101\n",
            "D: -0.616715133190155\n",
            "GP: 0.07871241867542267\n",
            "Gradient norm: 1.0116469860076904\n",
            "G: -0.13736435770988464\n",
            "Iteration 151\n",
            "D: -0.6203398704528809\n",
            "GP: 0.10576960444450378\n",
            "Gradient norm: 1.0191724300384521\n",
            "G: -0.12001709640026093\n",
            "Iteration 201\n",
            "D: -0.6473230123519897\n",
            "GP: 0.03942985087633133\n",
            "Gradient norm: 1.0126640796661377\n",
            "G: -0.1259734034538269\n",
            "Iteration 251\n",
            "D: -0.6949504017829895\n",
            "GP: 0.04293039068579674\n",
            "Gradient norm: 0.9890197515487671\n",
            "G: -0.1298096477985382\n",
            "Iteration 301\n",
            "D: -0.7108387351036072\n",
            "GP: 0.033714208751916885\n",
            "Gradient norm: 0.9954767823219299\n",
            "G: -0.14078453183174133\n",
            "Iteration 351\n",
            "D: -0.7323513627052307\n",
            "GP: 0.0560619980096817\n",
            "Gradient norm: 0.9945708513259888\n",
            "G: -0.10198087990283966\n",
            "Iteration 401\n",
            "D: -0.6247133016586304\n",
            "GP: 0.03186240419745445\n",
            "Gradient norm: 0.9856386780738831\n",
            "G: -0.15542297065258026\n",
            "Iteration 451\n",
            "D: -0.6024621725082397\n",
            "GP: 0.03623519465327263\n",
            "Gradient norm: 0.9943268299102783\n",
            "G: -0.14302441477775574\n",
            "Iteration 501\n",
            "D: -0.5848678946495056\n",
            "GP: 0.07650501281023026\n",
            "Gradient norm: 0.9862488508224487\n",
            "G: -0.13116024434566498\n",
            "Iteration 551\n",
            "D: -0.6248413324356079\n",
            "GP: 0.05540452152490616\n",
            "Gradient norm: 1.0116801261901855\n",
            "G: -0.17940907180309296\n",
            "Iteration 601\n",
            "D: -0.6226666569709778\n",
            "GP: 0.06201864778995514\n",
            "Gradient norm: 0.9825610518455505\n",
            "G: -0.11777061223983765\n",
            "Iteration 651\n",
            "D: -0.6537436246871948\n",
            "GP: 0.05375053733587265\n",
            "Gradient norm: 0.9854707717895508\n",
            "G: -0.13121774792671204\n",
            "Iteration 701\n",
            "D: -0.6390935182571411\n",
            "GP: 0.0704863965511322\n",
            "Gradient norm: 0.9680843353271484\n",
            "G: -0.1287773847579956\n",
            "Iteration 751\n",
            "D: -0.6618391275405884\n",
            "GP: 0.05175493657588959\n",
            "Gradient norm: 0.9878778457641602\n",
            "G: -0.11867643892765045\n",
            "Iteration 801\n",
            "D: -0.671642541885376\n",
            "GP: 0.08293947577476501\n",
            "Gradient norm: 0.9868773221969604\n",
            "G: -0.10034990310668945\n",
            "Iteration 851\n",
            "D: -0.6783083081245422\n",
            "GP: 0.05889531224966049\n",
            "Gradient norm: 1.0130324363708496\n",
            "G: -0.10961658507585526\n",
            "Iteration 901\n",
            "D: -0.5537471175193787\n",
            "GP: 0.11865063011646271\n",
            "Gradient norm: 0.9991970658302307\n",
            "G: -0.13852621614933014\n",
            "\n",
            "Epoch 23\n",
            "Iteration 1\n",
            "D: -0.702012300491333\n",
            "GP: 0.04729393497109413\n",
            "Gradient norm: 1.0024291276931763\n",
            "G: -0.11404693871736526\n",
            "Iteration 51\n",
            "D: -0.6363404989242554\n",
            "GP: 0.11747773736715317\n",
            "Gradient norm: 1.0055289268493652\n",
            "G: -0.10147114843130112\n",
            "Iteration 101\n",
            "D: -0.6711804866790771\n",
            "GP: 0.06690453737974167\n",
            "Gradient norm: 0.9916715621948242\n",
            "G: -0.11612856388092041\n",
            "Iteration 151\n",
            "D: -0.5925863981246948\n",
            "GP: 0.10363848507404327\n",
            "Gradient norm: 0.9881991744041443\n",
            "G: -0.14743782579898834\n",
            "Iteration 201\n",
            "D: -0.6391405463218689\n",
            "GP: 0.05161783844232559\n",
            "Gradient norm: 1.0041835308074951\n",
            "G: -0.1628008484840393\n",
            "Iteration 251\n",
            "D: -0.6367452144622803\n",
            "GP: 0.0651339441537857\n",
            "Gradient norm: 1.0016356706619263\n",
            "G: -0.1513374298810959\n",
            "Iteration 301\n",
            "D: -0.5103532075881958\n",
            "GP: 0.09463609755039215\n",
            "Gradient norm: 0.9899696111679077\n",
            "G: -0.22620707750320435\n",
            "Iteration 351\n",
            "D: -0.5605326890945435\n",
            "GP: 0.06432092934846878\n",
            "Gradient norm: 0.9831442832946777\n",
            "G: -0.2360432744026184\n",
            "Iteration 401\n",
            "D: -0.6611734628677368\n",
            "GP: 0.05731882527470589\n",
            "Gradient norm: 0.9960042834281921\n",
            "G: -0.14269103109836578\n",
            "Iteration 451\n",
            "D: -0.7411038279533386\n",
            "GP: 0.06701003760099411\n",
            "Gradient norm: 0.9782781004905701\n",
            "G: -0.11182377487421036\n",
            "Iteration 501\n",
            "D: -0.7221014499664307\n",
            "GP: 0.03821824491024017\n",
            "Gradient norm: 1.0087525844573975\n",
            "G: -0.14226384460926056\n",
            "Iteration 551\n",
            "D: -0.6573920249938965\n",
            "GP: 0.04893537610769272\n",
            "Gradient norm: 0.9953715205192566\n",
            "G: -0.16867688298225403\n",
            "Iteration 601\n",
            "D: -0.5174877643585205\n",
            "GP: 0.12032151222229004\n",
            "Gradient norm: 1.0071072578430176\n",
            "G: -0.1656317561864853\n",
            "Iteration 651\n",
            "D: -0.44252294301986694\n",
            "GP: 0.10219909250736237\n",
            "Gradient norm: 1.0202453136444092\n",
            "G: -0.22940696775913239\n",
            "Iteration 701\n",
            "D: -0.35886067152023315\n",
            "GP: 0.18640542030334473\n",
            "Gradient norm: 1.0371737480163574\n",
            "G: -0.22676712274551392\n",
            "Iteration 751\n",
            "D: -0.5314399600028992\n",
            "GP: 0.09263735264539719\n",
            "Gradient norm: 0.9914309978485107\n",
            "G: -0.1972178965806961\n",
            "Iteration 801\n",
            "D: -0.5408241152763367\n",
            "GP: 0.07764357328414917\n",
            "Gradient norm: 0.9982266426086426\n",
            "G: -0.13814318180084229\n",
            "Iteration 851\n",
            "D: -0.4908050000667572\n",
            "GP: 0.11606083065271378\n",
            "Gradient norm: 1.0002315044403076\n",
            "G: -0.1606973111629486\n",
            "Iteration 901\n",
            "D: -0.49731558561325073\n",
            "GP: 0.14611808955669403\n",
            "Gradient norm: 0.9709213376045227\n",
            "G: -0.1529998928308487\n",
            "\n",
            "Epoch 24\n",
            "Iteration 1\n",
            "D: -0.5388942360877991\n",
            "GP: 0.1416139006614685\n",
            "Gradient norm: 1.0036168098449707\n",
            "G: -0.14562903344631195\n",
            "Iteration 51\n",
            "D: -0.5471630096435547\n",
            "GP: 0.07101761549711227\n",
            "Gradient norm: 0.9836931228637695\n",
            "G: -0.15736067295074463\n",
            "Iteration 101\n",
            "D: -0.5675185322761536\n",
            "GP: 0.09238569438457489\n",
            "Gradient norm: 1.0121227502822876\n",
            "G: -0.13536334037780762\n",
            "Iteration 151\n",
            "D: -0.47577372193336487\n",
            "GP: 0.18837395310401917\n",
            "Gradient norm: 0.9735193252563477\n",
            "G: -0.12339463829994202\n",
            "Iteration 201\n",
            "D: -0.515270471572876\n",
            "GP: 0.15539468824863434\n",
            "Gradient norm: 1.0067956447601318\n",
            "G: -0.17545345425605774\n",
            "Iteration 251\n",
            "D: -0.6414527297019958\n",
            "GP: 0.05640348419547081\n",
            "Gradient norm: 0.9861236810684204\n",
            "G: -0.14695040881633759\n",
            "Iteration 301\n",
            "D: -0.544731855392456\n",
            "GP: 0.05473518744111061\n",
            "Gradient norm: 0.9866279363632202\n",
            "G: -0.15459084510803223\n",
            "Iteration 351\n",
            "D: -0.6700184345245361\n",
            "GP: 0.034831203520298004\n",
            "Gradient norm: 0.9871147871017456\n",
            "G: -0.14486214518547058\n",
            "Iteration 401\n",
            "D: -0.6837984323501587\n",
            "GP: 0.05418315529823303\n",
            "Gradient norm: 1.0190680027008057\n",
            "G: -0.1207340806722641\n",
            "Iteration 451\n",
            "D: -0.6442252993583679\n",
            "GP: 0.0779598280787468\n",
            "Gradient norm: 1.0030360221862793\n",
            "G: -0.10430131107568741\n",
            "Iteration 501\n",
            "D: -0.7253551483154297\n",
            "GP: 0.060402125120162964\n",
            "Gradient norm: 0.9839915633201599\n",
            "G: -0.09242600947618484\n",
            "Iteration 551\n",
            "D: -0.6568057537078857\n",
            "GP: 0.10887578129768372\n",
            "Gradient norm: 0.9860472679138184\n",
            "G: -0.10056980699300766\n",
            "Iteration 601\n",
            "D: -0.6231144666671753\n",
            "GP: 0.062125593423843384\n",
            "Gradient norm: 0.9948389530181885\n",
            "G: -0.1473097801208496\n",
            "Iteration 651\n",
            "D: -0.5346837639808655\n",
            "GP: 0.05282086133956909\n",
            "Gradient norm: 1.010451316833496\n",
            "G: -0.23802533745765686\n",
            "Iteration 701\n",
            "D: -0.6162385940551758\n",
            "GP: 0.0484929159283638\n",
            "Gradient norm: 1.0051538944244385\n",
            "G: -0.1786753535270691\n",
            "Iteration 751\n",
            "D: -0.5708991289138794\n",
            "GP: 0.09530697017908096\n",
            "Gradient norm: 0.9840954542160034\n",
            "G: -0.14528125524520874\n",
            "Iteration 801\n",
            "D: -0.6338943243026733\n",
            "GP: 0.09901782870292664\n",
            "Gradient norm: 0.9805848598480225\n",
            "G: -0.11659515649080276\n",
            "Iteration 851\n",
            "D: -0.6959260702133179\n",
            "GP: 0.03898047283291817\n",
            "Gradient norm: 1.010901927947998\n",
            "G: -0.1394668072462082\n",
            "Iteration 901\n",
            "D: -0.6890981197357178\n",
            "GP: 0.08885458111763\n",
            "Gradient norm: 0.9810987114906311\n",
            "G: -0.13144806027412415\n",
            "\n",
            "Epoch 25\n",
            "Iteration 1\n",
            "D: -0.6995230317115784\n",
            "GP: 0.058138154447078705\n",
            "Gradient norm: 1.006354808807373\n",
            "G: -0.10645218193531036\n"
          ]
        }
      ],
      "source": [
        "data_loader, _ = get_mnist_dataloaders(batch_size=64)\n",
        "img_size = (32, 32, 1)\n",
        "\n",
        "generator = Generator(img_size=img_size, latent_dim=100, dim=16)\n",
        "discriminator = Discriminator(img_size=img_size, dim=16)\n",
        "\n",
        "print(generator)\n",
        "print(discriminator)\n",
        "\n",
        "# Initialize optimizers\n",
        "lr = 1e-4\n",
        "betas = (.9, .99)\n",
        "G_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=betas)\n",
        "D_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=betas)\n",
        "\n",
        "# Train model\n",
        "epochs = 200\n",
        "trainer = Trainer(generator, discriminator, G_optimizer, D_optimizer,\n",
        "                  use_cuda=torch.cuda.is_available())\n",
        "trainer.train(data_loader, epochs, save_training_gif=True)\n",
        "\n",
        "# Save models\n",
        "name = 'mnist_model'\n",
        "torch.save(trainer.G.state_dict(), './gen_' + name + '.pt')\n",
        "torch.save(trainer.D.state_dict(), './dis_' + name + '.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
