{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from datetime import datetime\n",
        "import keras\n",
        "from keras import layers, ops\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time"
      ],
      "metadata": {
        "id": "6FT_YDowi69w"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "dataset_name = \"mnist\"\n",
        "dataset_repetitions = 5\n",
        "num_epochs = 50\n",
        "image_size = 64\n",
        "batch_size = 64\n",
        "latent_dim = 100\n",
        "\n",
        "# WGAN specific\n",
        "critic_iterations = 5  # Train critic 5 times per generator update\n",
        "clip_value = 0.01  # Weight clipping value for WGAN\n",
        "learning_rate = 5e-5  # Lower learning rate for WGAN stability"
      ],
      "metadata": {
        "id": "Q8cN5xSai_to"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(data):\n",
        "    \"\"\"Preprocess image: resize, convert to RGB, normalize to [0, 1]\"\"\"\n",
        "    image = data[\"image\"]\n",
        "\n",
        "    # MNIST is 28x28 grayscale, convert to 3 channels\n",
        "    if len(image.shape) == 2 or image.shape[-1] == 1:\n",
        "        image = tf.image.grayscale_to_rgb(image)\n",
        "\n",
        "    # MNIST is already 28x28, but resize if needed\n",
        "    image = tf.image.resize(image, size=[image_size, image_size], antialias=True)\n",
        "    return ops.clip(image / 255.0, 0.0, 1.0)\n",
        "\n",
        "\n",
        "def prepare_dataset(split):\n",
        "    \"\"\"Prepare dataset with preprocessing and batching\"\"\"\n",
        "    return (\n",
        "        tfds.load(dataset_name, split=split, shuffle_files=True)\n",
        "        .map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        .cache()\n",
        "        .repeat(dataset_repetitions)\n",
        "        .shuffle(10 * batch_size)\n",
        "        .batch(batch_size, drop_remainder=True)\n",
        "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "# Use test split for KID validation (MNIST has train/test)\n",
        "kid_val_ds = prepare_dataset(\"test\")\n",
        "kid_val_iter = iter(kid_val_ds)"
      ],
      "metadata": {
        "id": "27YjCnjZjFwm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KIDMetric(keras.metrics.Metric):\n",
        "    \"\"\"\n",
        "    Unbiased KID (Kernel Inception Distance) with polynomial kernel of degree 3.\n",
        "    KID = E[k(x,x')] + E[k(y,y')] - 2E[k(x,y)], x=real features, y=fake features\n",
        "    Uses InceptionV3 (avg pooled) as the encoder.\n",
        "    \"\"\"\n",
        "    def __init__(self, image_size=64, kid_image_size=299, name=\"kid\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.kid_tracker = keras.metrics.Mean(name=\"kid_tracker\")\n",
        "        self.kid_image_size = kid_image_size\n",
        "\n",
        "        # Inception encoder: [0,1] -> [0,255] -> preprocess_input -> InceptionV3 -> GAP(2048)\n",
        "        self.encoder = keras.Sequential(\n",
        "            [\n",
        "                keras.Input(shape=(image_size, image_size, 3)),\n",
        "                layers.Rescaling(255.0),\n",
        "                layers.Resizing(kid_image_size, kid_image_size),\n",
        "                layers.Lambda(keras.applications.inception_v3.preprocess_input),\n",
        "                keras.applications.InceptionV3(\n",
        "                    include_top=False,\n",
        "                    input_shape=(kid_image_size, kid_image_size, 3),\n",
        "                    weights=\"imagenet\",\n",
        "                ),\n",
        "                layers.GlobalAveragePooling2D(),\n",
        "            ],\n",
        "            name=\"inception_encoder\",\n",
        "        )\n",
        "\n",
        "    def polynomial_kernel(self, feats1, feats2):\n",
        "        # k(x,y) = (xᵀy / d + 1)^3\n",
        "        d = ops.cast(ops.shape(feats1)[1], \"float32\")\n",
        "        return (feats1 @ ops.transpose(feats2) / d + 1.0) ** 3.0\n",
        "\n",
        "    def _unbiased_mmd(self, f_real, f_fake):\n",
        "        # Gram matrices\n",
        "        k_xx = self.polynomial_kernel(f_real, f_real)\n",
        "        k_yy = self.polynomial_kernel(f_fake, f_fake)\n",
        "        k_xy = self.polynomial_kernel(f_real, f_fake)\n",
        "\n",
        "        m = tf.shape(f_real)[0]\n",
        "        n = tf.shape(f_fake)[0]\n",
        "\n",
        "        # remove diagonal terms for unbiased estimate\n",
        "        sum_k_xx = (tf.reduce_sum(k_xx) - tf.reduce_sum(tf.linalg.diag_part(k_xx))) / tf.cast(m * (m - 1), tf.float32)\n",
        "        sum_k_yy = (tf.reduce_sum(k_yy) - tf.reduce_sum(tf.linalg.diag_part(k_yy))) / tf.cast(n * (n - 1), tf.float32)\n",
        "        sum_k_xy = tf.reduce_sum(k_xy) / tf.cast(m * n, tf.float32)\n",
        "\n",
        "        return sum_k_xx + sum_k_yy - 2.0 * sum_k_xy\n",
        "\n",
        "    def update_state(self, real_images, generated_images, sample_weight=None):\n",
        "        # Expect inputs in [0,1]. If your generator outputs [-1,1] via tanh,\n",
        "        # convert: gen = (gen + 1.0) / 2.0 before calling update_state.\n",
        "        f_real = self.encoder(real_images, training=False)\n",
        "        f_fake = self.encoder(generated_images, training=False)\n",
        "        kid = self._unbiased_mmd(f_real, f_fake)\n",
        "        self.kid_tracker.update_state(kid)\n",
        "\n",
        "    def result(self):\n",
        "        return self.kid_tracker.result()\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.kid_tracker.reset_state()\n",
        "\n",
        "# --- KID generation helper ---\n",
        "latent_dim = 100  # keep whatever your WGAN uses\n",
        "\n",
        "def gen_fake_batch(generator, batch_size):\n",
        "    z = tf.random.normal(shape=(batch_size, latent_dim))\n",
        "    fake = generator(z, training=False)\n",
        "    # Map to [0,1] if your generator uses tanh output in [-1,1]\n",
        "    if fake.dtype.is_floating:\n",
        "        # Heuristic: if values look like tanh, rescale\n",
        "        # (safe to always rescale if you know you're using tanh)\n",
        "        fake = (fake + 1.0) / 2.0\n",
        "    return tf.clip_by_value(fake, 0.0, 1.0)\n"
      ],
      "metadata": {
        "id": "XI5at3vAjOJD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets - use train split for MNIST\n",
        "train_dataset = prepare_dataset(\"train\")\n",
        "# Print out a sample of the dataset\n",
        "for image in train_dataset.take(1):\n",
        "    plt.imshow(image[0].numpy())\n",
        "    plt.show()\n",
        "    break\n",
        "\n",
        "\n",
        "def build_generator(latent_dim, image_size):\n",
        "    \"\"\"Build generator network\"\"\"\n",
        "    model = keras.Sequential([\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        layers.Dense(4 * 4 * 256, use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Reshape((4, 4, 256)),\n",
        "\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "\n",
        "        layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "\n",
        "        layers.Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "\n",
        "        layers.Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', use_bias=False),\n",
        "        layers.Activation('tanh'),  # Output in [-1, 1]\n",
        "    ], name='generator')\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_critic(image_size):\n",
        "    \"\"\"WGAN-GP critic: no BatchNorm/Dropout; plain conv stack.\"\"\"\n",
        "    L = keras.layers\n",
        "    x = inputs = keras.Input(shape=(image_size, image_size, 3))\n",
        "    nf = 64\n",
        "    # 64 -> 32\n",
        "    x = L.Conv2D(nf, 4, strides=2, padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
        "    x = L.LeakyReLU(0.2)(x)\n",
        "    # 32 -> 16\n",
        "    x = L.Conv2D(nf*2, 4, strides=2, padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
        "    x = L.LeakyReLU(0.2)(x)\n",
        "    # 16 -> 8\n",
        "    x = L.Conv2D(nf*4, 4, strides=2, padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
        "    x = L.LeakyReLU(0.2)(x)\n",
        "    # 8 -> 4\n",
        "    x = L.Conv2D(nf*8, 4, strides=2, padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
        "    x = L.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = L.Flatten()(x)\n",
        "    out = L.Dense(1)(x)  # linear score\n",
        "    return keras.Model(inputs, out, name=\"critic\")\n",
        "\n",
        "# Gradient penalty hyperparam\n",
        "gp_lambda = 10.0\n",
        "\n",
        "def gradient_penalty(critic, real, fake):\n",
        "    \"\"\"WGAN-GP gradient penalty on random interpolates\"\"\"\n",
        "    batch = tf.shape(real)[0]\n",
        "    epsilon = tf.random.uniform([batch, 1, 1, 1], 0.0, 1.0)\n",
        "    x_hat = epsilon * real + (1.0 - epsilon) * fake\n",
        "    with tf.GradientTape() as gp_tape:\n",
        "        gp_tape.watch(x_hat)\n",
        "        pred = critic(x_hat, training=True)\n",
        "    grads = gp_tape.gradient(pred, x_hat)  # ∂D/∂x_hat\n",
        "    grads = tf.reshape(grads, [batch, -1])\n",
        "    grad_norm = tf.norm(grads, axis=1)\n",
        "    gp = tf.reduce_mean((grad_norm - 1.0) ** 2)\n",
        "    return gp\n",
        "\n",
        "\n",
        "def generate_images(generator, epoch, num_images=16):\n",
        "    \"\"\"Generate and save sample images\"\"\"\n",
        "    # Generate random noise\n",
        "    noise = tf.random.normal((num_images, latent_dim))\n",
        "\n",
        "    # Generate images\n",
        "    generated_images = G_ema(noise, training=False)\n",
        "\n",
        "    # Convert from [-1, 1] to [0, 1] for display\n",
        "    generated_images = (generated_images + 1) / 2.0\n",
        "    generated_images = ops.clip(generated_images, 0.0, 1.0)\n",
        "\n",
        "    # Create output directory\n",
        "    output_dir = \"generated_images\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Plot grid\n",
        "    fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(generated_images[i].numpy())\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save figure\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    filename = f\"epoch_{epoch:03d}_{timestamp}.png\"\n",
        "    filepath = os.path.join(output_dir, filename)\n",
        "    plt.savefig(filepath)\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Saved generated images to {filepath}\")\n",
        "\n",
        "# Helper function for ema\n",
        "def update_ema(G_src, G_tgt, decay=0.999):\n",
        "    \"\"\"G_tgt = EMA(G_src)  (in-place)\"\"\"\n",
        "    src_w = G_src.get_weights()\n",
        "    tgt_w = G_tgt.get_weights()\n",
        "    new_w = []\n",
        "    for w_ema, w in zip(tgt_w, src_w):\n",
        "        new_w.append(decay * w_ema + (1.0 - decay) * w)\n",
        "    G_tgt.set_weights(new_w)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "r6mZCxpOjUV6",
        "outputId": "80919bfb-ae8d-4ec1-d108-d43da068d1fb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-SrD72SVI_OM",
        "outputId": "1b79e5b3-c02e-4da4-ffef-465fd8a6491d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator summary:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"generator\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"generator\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │       \u001b[38;5;34m409,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_196         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │        \u001b[38;5;34m16,384\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_16 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_8              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m524,288\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_197         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_17 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_9              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │       \u001b[38;5;34m131,072\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_198         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_18 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_10             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m32,768\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_199         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_19 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_11             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │         \u001b[38;5;34m1,536\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_190 (\u001b[38;5;33mActivation\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">409,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_196         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_8              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_197         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_9              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_198         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_10             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_199         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_11             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_190 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,116,544\u001b[0m (4.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,116,544</span> (4.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,107,904\u001b[0m (4.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,107,904</span> (4.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,640\u001b[0m (33.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,640</span> (33.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Critic summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"critic\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"critic\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_196 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m3,136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_20 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_197 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m131,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_21 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_198 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m524,544\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_22 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_199 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,097,664\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_23 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m8,193\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_196 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_197 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_198 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_199 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,193</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,764,737\u001b[0m (10.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,764,737</span> (10.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,764,737\u001b[0m (10.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,764,737</span> (10.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training...\n",
            "\n",
            "Epoch 1/50\n",
            "  Step 0: D_loss=-24.7471 G_loss=-2.3814 W=26.3818 GP=0.1635\n",
            "  Step 100: D_loss=-129.5925 G_loss=-168.9009 W=189.2859 GP=5.9693\n",
            "  Step 200: D_loss=-56.5732 G_loss=-149.4344 W=79.8400 GP=2.3267\n",
            "  Step 300: D_loss=-37.3708 G_loss=-63.6625 W=52.2541 GP=1.4883\n",
            "  Step 400: D_loss=-35.1173 G_loss=-37.5830 W=48.8512 GP=1.3734\n",
            "  Step 500: D_loss=-33.0307 G_loss=-16.1452 W=45.8702 GP=1.2839\n",
            "  Step 600: D_loss=-31.1755 G_loss=-25.2782 W=42.6112 GP=1.1436\n",
            "  Step 700: D_loss=-30.2888 G_loss=-20.7902 W=40.5359 GP=1.0247\n",
            "  Step 800: D_loss=-30.6969 G_loss=-14.8456 W=39.8948 GP=0.9198\n",
            "  Step 900: D_loss=-29.0923 G_loss=-0.8313 W=40.0893 GP=1.0997\n",
            "  Step 1000: D_loss=-26.8331 G_loss=-7.5356 W=34.3407 GP=0.7508\n",
            "  Step 1100: D_loss=-26.7984 G_loss=-11.7093 W=34.2616 GP=0.7463\n",
            "  Step 1200: D_loss=-24.2001 G_loss=1.9123 W=32.7025 GP=0.8502\n"
          ]
        }
      ],
      "source": [
        "# Build models\n",
        "generator = build_generator(latent_dim, image_size)\n",
        "critic = build_critic(image_size)\n",
        "\n",
        "# --- EMA setup (place right after you build `generator`) ---\n",
        "G_ema = keras.models.clone_model(generator)\n",
        "G_ema.set_weights(generator.get_weights())\n",
        "ema_decay = 0.999  # try 0.999 for 50 epochs; 0.9995 if you train longer\n",
        "\n",
        "# Optimizers - Adam instead of RMSProp\n",
        "generator_optimizer = keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.0, beta_2=0.9)\n",
        "critic_optimizer    = keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.0, beta_2=0.9)\n",
        "\n",
        "print(\"Generator summary:\")\n",
        "generator.summary()\n",
        "print(\"\\nCritic summary:\")\n",
        "critic.summary()\n",
        "\n",
        "\n",
        "# Training step\n",
        "@tf.function\n",
        "def train_step(real_images):\n",
        "    batch_size = tf.shape(real_images)[0]\n",
        "    real_images = real_images * 2.0 - 1.0  # [-1,1]\n",
        "\n",
        "    # --- Critic updates ---\n",
        "    for _ in range(critic_iterations):\n",
        "        noise = tf.random.normal((batch_size, latent_dim))\n",
        "        fake_images = generator(noise, training=True)  # training=True OK\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            real_scores = critic(real_images, training=True)\n",
        "            fake_scores = critic(fake_images, training=True)\n",
        "\n",
        "            wasserstein = tf.reduce_mean(real_scores) - tf.reduce_mean(fake_scores)\n",
        "            gp = gradient_penalty(critic, real_images, fake_images)\n",
        "            # We minimize the negative of wasserstein + GP term\n",
        "            critic_loss = -(wasserstein) + gp_lambda * gp\n",
        "\n",
        "        grads = tape.gradient(critic_loss, critic.trainable_weights)\n",
        "        critic_optimizer.apply_gradients(zip(grads, critic.trainable_weights))\n",
        "\n",
        "    # --- Generator update ---\n",
        "    noise = tf.random.normal((batch_size, latent_dim))\n",
        "    with tf.GradientTape() as tape:\n",
        "        fake_images = generator(noise, training=True)\n",
        "        fake_scores = critic(fake_images, training=True)  # train mode since no BN/Dropout\n",
        "        generator_loss = -tf.reduce_mean(fake_scores)\n",
        "    g_grads = tape.gradient(generator_loss, generator.trainable_weights)\n",
        "    generator_optimizer.apply_gradients(zip(g_grads, generator.trainable_weights))\n",
        "\n",
        "    # For logging, you might also return components:\n",
        "    return critic_loss, generator_loss, wasserstein, gp\n",
        "\n",
        "\n",
        "# --- Initialize KID metric ---\n",
        "kid_metric = KIDMetric(image_size=image_size, kid_image_size=299)\n",
        "kid_history = []\n",
        "\n",
        "# Create validation iterator (already defined above)\n",
        "kid_val_iter = iter(kid_val_ds)\n",
        "\n",
        "\n",
        "\n",
        "# Training loop + KID eval (per epoch)\n",
        "print(\"\\nStarting training...\")\n",
        "\n",
        "# Start overall timing\n",
        "training_start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "    # Start epoch timing\n",
        "    epoch_start_time = time.time()\n",
        "\n",
        "    epoch_critic_loss = []\n",
        "    epoch_generator_loss = []\n",
        "\n",
        "    for step, batch_images in enumerate(train_dataset):\n",
        "        critic_loss, generator_loss, W, gp_val = train_step(batch_images)\n",
        "        update_ema(generator, G_ema, decay=ema_decay)\n",
        "\n",
        "        epoch_critic_loss.append(critic_loss.numpy())\n",
        "        epoch_generator_loss.append(generator_loss.numpy())\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print(\n",
        "                f\"  Step {step}: D_loss={critic_loss:.4f} G_loss={generator_loss:.4f} \"\n",
        "                f\"W={W:.4f} GP={gp_val:.4f}\"\n",
        "            )\n",
        "\n",
        "    # Epoch training time\n",
        "    epoch_train_time = time.time() - epoch_start_time\n",
        "\n",
        "    # Print epoch averages\n",
        "    avg_critic_loss = np.mean(epoch_critic_loss)\n",
        "    avg_generator_loss = np.mean(epoch_generator_loss)\n",
        "    print(\n",
        "        f\"  Epoch {epoch + 1} - Avg Critic Loss: {avg_critic_loss:.4f}, \"\n",
        "        f\"Avg Generator Loss: {avg_generator_loss:.4f}\"\n",
        "    )\n",
        "\n",
        "    # --------- KID EVAL (every epoch) ----------\n",
        "    print(f\"  Computing KID for epoch {epoch + 1}...\")\n",
        "    kid_start_time = time.time()\n",
        "\n",
        "    # Get a real batch from validation split\n",
        "    try:\n",
        "        real_eval = next(kid_val_iter)\n",
        "    except StopIteration:\n",
        "        kid_val_iter = iter(kid_val_ds)\n",
        "        real_eval = next(kid_val_iter)\n",
        "\n",
        "    # Generate a fake batch using EMA generator\n",
        "    fake_eval = gen_fake_batch(G_ema, tf.shape(real_eval)[0])\n",
        "\n",
        "    # Update KID and log it\n",
        "    kid_metric.update_state(real_eval, fake_eval)\n",
        "    current_kid = float(kid_metric.result().numpy())\n",
        "    kid_eval_time = time.time() - kid_start_time\n",
        "\n",
        "    kid_history.append({\n",
        "        \"epoch\": int(epoch + 1),\n",
        "        \"kid\": current_kid,\n",
        "        \"epoch_train_time_sec\": epoch_train_time,\n",
        "        \"kid_eval_time_sec\": kid_eval_time,\n",
        "        \"avg_critic_loss\": float(avg_critic_loss),\n",
        "        \"avg_generator_loss\": float(avg_generator_loss)\n",
        "    })\n",
        "\n",
        "    print(f\"  [KID] Epoch {epoch+1}: KID={current_kid:.6f} (eval time: {kid_eval_time:.2f}s)\")\n",
        "    kid_metric.reset_state()\n",
        "    # ------------------------------------------------------\n",
        "\n",
        "    # Generate and save sample images every epoch\n",
        "    sampling_start_time = time.time()\n",
        "    generate_images(generator, epoch + 1)\n",
        "    sampling_time = time.time() - sampling_start_time\n",
        "\n",
        "    # Update history with sampling time\n",
        "    kid_history[-1][\"sampling_time_sec\"] = sampling_time\n",
        "\n",
        "    print(f\"  Epoch time: {epoch_train_time:.2f}s, Sampling time: {sampling_time:.2f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate total training time\n",
        "total_training_time = time.time() - training_start_time\n",
        "print(f\"\\nTotal training time: {total_training_time:.2f} seconds ({total_training_time/60:.2f} minutes)\")\n",
        "\n",
        "# Save models\n",
        "print(\"\\nSaving models...\")\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "generator.save_weights(\"checkpoints/wgan_generator.weights.h5\")\n",
        "critic.save_weights(\"checkpoints/wgan_critic.weights.h5\")\n",
        "print(\"Models saved!\")\n",
        "\n",
        "# ---- Save metrics history to compare with DDIM ----\n",
        "import json\n",
        "\n",
        "# Save as JSON (full data)\n",
        "with open(\"wgan_metrics.json\", \"w\") as f:\n",
        "    json.dump(kid_history, f, indent=2)\n",
        "\n",
        "# Save as CSV with specific column order: epoch, KID, training time, sampling time\n",
        "df_metrics = pd.DataFrame(kid_history)\n",
        "# Reorder columns for the CSV\n",
        "df_csv = df_metrics[['epoch', 'kid', 'epoch_train_time_sec', 'sampling_time_sec']].copy()\n",
        "# Rename columns for clarity\n",
        "df_csv.columns = ['Epoch', 'KID', 'Training_Time_Sec', 'Sampling_Time_Sec']\n",
        "df_csv.to_csv(\"wgan_metrics.csv\", index=False)\n",
        "\n",
        "# Print summary statistics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total training time: {total_training_time:.2f}s ({total_training_time/60:.2f} min)\")\n",
        "print(f\"Average epoch time: {df_metrics['epoch_train_time_sec'].mean():.2f}s\")\n",
        "print(f\"Average sampling time: {df_metrics['sampling_time_sec'].mean():.2f}s\")\n",
        "print(f\"Average KID eval time: {df_metrics['kid_eval_time_sec'].mean():.2f}s\")\n",
        "print(f\"\\nFinal KID: {df_metrics['kid'].iloc[-1]:.6f}\")\n",
        "print(f\"Best KID: {df_metrics['kid'].min():.6f} (Epoch {df_metrics.loc[df_metrics['kid'].idxmin(), 'epoch']:.0f})\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nMetrics saved to:\")\n",
        "print(f\"  - wgan_metrics.csv\")\n",
        "print(f\"  - wgan_metrics.json\")\n",
        "print(\"\\nTraining complete!\")"
      ],
      "metadata": {
        "id": "2vBP5rYIjeAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate final high-quality images after training\n",
        "print(\"Generating final images...\")\n",
        "\n",
        "# Create output directory\n",
        "final_output_dir = \"final_generated_images\"\n",
        "os.makedirs(final_output_dir, exist_ok=True)\n",
        "\n",
        "# Generate multiple sets of images\n",
        "num_sets = 5  # Generate 5 sets of 16 images each\n",
        "num_images_per_set = 16\n",
        "\n",
        "for set_idx in range(num_sets):\n",
        "    # Generate random noise\n",
        "    noise = tf.random.normal((num_images_per_set, latent_dim))\n",
        "\n",
        "    # Generate images using EMA generator (best quality)\n",
        "    generated_images = G_ema(noise, training=False)\n",
        "\n",
        "    # Convert from [-1, 1] to [0, 1] for display\n",
        "    generated_images = (generated_images + 1) / 2.0\n",
        "    generated_images = ops.clip(generated_images, 0.0, 1.0)\n",
        "\n",
        "    # Plot grid (4x4)\n",
        "    fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(generated_images[i].numpy())\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save figure\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    filename = f\"final_set_{set_idx+1}_{timestamp}.png\"\n",
        "    filepath = os.path.join(final_output_dir, filename)\n",
        "    plt.savefig(filepath, dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"  Saved set {set_idx+1}/{num_sets} to {filepath}\")\n",
        "\n",
        "print(f\"\\n✓ Generated {num_sets} sets of images in '{final_output_dir}/' folder\")\n",
        "print(f\"Total images: {num_sets * num_images_per_set} images\")\n"
      ],
      "metadata": {
        "id": "0lmKxzOlkYDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    !zip -r generated_images.zip generated_images"
      ],
      "metadata": {
        "id": "cA17SfoZlm3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    from google.colab import files\n",
        "    files.download('generated_images.zip')"
      ],
      "metadata": {
        "id": "Yjucysn_z4oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    !zip -r final_generated_images.zip final_generated_images"
      ],
      "metadata": {
        "id": "8Dg_dZ0o0CKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  files.download('final_generated_images.zip')"
      ],
      "metadata": {
        "id": "hjLAcatD0H0X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}